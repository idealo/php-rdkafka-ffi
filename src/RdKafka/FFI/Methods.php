<?php
/**
 * This file is generated! Do not edit directly.
 */

declare(strict_types=1);

namespace RdKafka\FFI;

/**
 * Description of librdkafka methods and constants is extracted from the official documentation.
 * @link https://docs.confluent.io/current/clients/librdkafka/rdkafka_8h.html
 */
trait Methods 
{
    abstract public static function getFFI():\FFI;
    
    /**
     * <p>Returns the librdkafka version as integer. </p>
     * <dl class="section see"><dt>See also</dt><dd>See RD_KAFKA_VERSION for how to parse the integer format. </dd>
     * <dd>
     * Use rd_kafka_version_str() to retreive the version as a string. </dd></dl>
     * @return int|null int - ) - Version integer.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a83e363606ef2da2e91b7429b229dbc8e
     */
    public static function rd_kafka_version(): ?int
    {
        return static::getFFI()->rd_kafka_version();
    }

    /**
     * <p>Returns the librdkafka version as string. </p>
     * @return string|null const char* - ) - Version string
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a0cc60434083686fd8e379a905652d34a
     */
    public static function rd_kafka_version_str(): ?string
    {
        return static::getFFI()->rd_kafka_version_str();
    }

    /**
     * <p>Retrieve supported debug contexts for use with the <code>"debug"</code> configuration property. (runtime) </p>
     * @return string|null const char* - ) - Comma-separated list of available debugging contexts.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#adece97d3cbdd6ca936df5b0663118c45
     */
    public static function rd_kafka_get_debug_contexts(): ?string
    {
        return static::getFFI()->rd_kafka_get_debug_contexts();
    }

    /**
     * @param \FFI\CData|null $errdescs struct rd_kafka_err_desc**
     * @param \FFI\CData|null $cntp size_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_get_err_descs(?\FFI\CData $errdescs, ?\FFI\CData $cntp): void
    {
        static::getFFI()->rd_kafka_get_err_descs($errdescs, $cntp);
    }

    /**
     * <p>Returns a human readable representation of a kafka error. </p>
     * @param int $err rd_kafka_resp_err_t - ) - Error code to translate
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ab7bfc925e8d63851511b88a1cee94d6d
     */
    public static function rd_kafka_err2str(int $err): ?string
    {
        return static::getFFI()->rd_kafka_err2str($err);
    }

    /**
     * <p>Returns the error code name (enum name). </p>
     * @param int $err rd_kafka_resp_err_t - ) - Error code to translate
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a8d5f6f2775ec67b124abeb5dfada2d77
     */
    public static function rd_kafka_err2name(int $err): ?string
    {
        return static::getFFI()->rd_kafka_err2name($err);
    }

    /**
     * <p>Returns the last error code generated by a legacy API call in the current thread. </p>
     * <p>The legacy APIs are the ones using errno to propagate error value, namely:</p><ul><li>rd_kafka_topic_new()</li>
     * <li>rd_kafka_consume_start()</li>
     * <li>rd_kafka_consume_stop()</li>
     * <li>rd_kafka_consume()</li>
     * <li>rd_kafka_consume_batch()</li>
     * <li>rd_kafka_consume_callback()</li>
     * <li>rd_kafka_consume_queue()</li>
     * <li>rd_kafka_produce()</li>
     * </ul><p>The main use for this function is to avoid converting system <code>errno</code> values to rd_kafka_resp_err_t codes for legacy APIs.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>The last error is stored per-thread, if multiple rd_kafka_t handles are used in the same application thread the developer needs to make sure rd_kafka_last_error() is called immediately after a failed API call. </dd></dl>
     * @return int rd_kafka_resp_err_t - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ae7b90c323d460e0276d79f6ab69e93b7
     */
    public static function rd_kafka_last_error(): int
    {
        return static::getFFI()->rd_kafka_last_error();
    }

    /**
     * <p>Converts the system errno value <code>errnox</code> to a rd_kafka_resp_err_t error code upon failure from the following functions: </p>
     * <ul><li>rd_kafka_topic_new()</li>
     * <li>rd_kafka_consume_start()</li>
     * <li>rd_kafka_consume_stop()</li>
     * <li>rd_kafka_consume()</li>
     * <li>rd_kafka_consume_batch()</li>
     * <li>rd_kafka_consume_callback()</li>
     * <li>rd_kafka_consume_queue()</li>
     * <li>rd_kafka_produce()</li>
     * </ul><dl class="section remark"><dt>Remarks</dt><dd>A better alternative is to call rd_kafka_last_error() immediately after any of the above functions return -1 or NULL.</dd></dl><dl class="section see"><dt>See also</dt><dd>rd_kafka_last_error() </dd></dl>
     * @param int|null $errnox int - ) - System errno value to convert
     * @return int rd_kafka_resp_err_t - Appropriate error code for <code>errnox</code>
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a99c7d1faaa534befeedf23b55a88a40f
     */
    public static function rd_kafka_errno2err(?int $errnox): int
    {
        return static::getFFI()->rd_kafka_errno2err($errnox);
    }

    /**
     * <p>Returns the thread-local system errno. </p>
     * <p>On most platforms this is the same as <code>errno</code> but in case of different runtimes between library and application (e.g., Windows static DLLs) this provides a means for expsing the errno librdkafka uses.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>The value is local to the current calling thread. </dd></dl>
     * @return int|null int - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#aef27224d8c638e51f3ee29bb25f65f1f
     */
    public static function rd_kafka_errno(): ?int
    {
        return static::getFFI()->rd_kafka_errno();
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_fatal_error(?\FFI\CData $rk, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_fatal_error($rk, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int $err rd_kafka_resp_err_t
     * @param string|null $reason const char*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_test_fatal_error(?\FFI\CData $rk, int $err, ?string $reason): int
    {
        return static::getFFI()->rd_kafka_test_fatal_error($rk, $err, $reason);
    }

    /**
     * <p>Destroy a rd_kafka_topic_partition_t. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>This must not be called for elements in a topic partition list. </dd></dl>
     * @param \FFI\CData|null $rktpar rd_kafka_topic_partition_t* - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ac5a7b02e3af816cfacbcfa6468c40c9a
     */
    public static function rd_kafka_topic_partition_destroy(?\FFI\CData $rktpar): void
    {
        static::getFFI()->rd_kafka_topic_partition_destroy($rktpar);
    }

    /**
     * <p>Create a new list/vector Topic+Partition container. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Use rd_kafka_topic_partition_list_destroy() to free all resources in use by a list and the list itself. </dd></dl><dl class="section see"><dt>See also</dt><dd>rd_kafka_topic_partition_list_add() </dd></dl>
     * @param int|null $size int - ) - Initial allocated size used when the expected number of elements is known or can be estimated. Avoids reallocation and possibly relocation of the elems array.
     * @return \FFI\CData|null rd_kafka_topic_partition_list_t* - A newly allocated Topic+Partition list.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#afb87d24333b6ad5a7415b06882f06b2a
     */
    public static function rd_kafka_topic_partition_list_new(?int $size): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_topic_partition_list_new($size);
    }

    /**
     * @param \FFI\CData|null $rkparlist rd_kafka_topic_partition_list_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_partition_list_destroy(?\FFI\CData $rkparlist): void
    {
        static::getFFI()->rd_kafka_topic_partition_list_destroy($rkparlist);
    }

    /**
     * <p>Add topic+partition to list. </p>
     * @param \FFI\CData|null $rktparlist rd_kafka_topic_partition_list_t* - List to extend
     * @param string|null $topic const char* - Topic name (copied)
     * @param int|null $partition int32_t - Partition id
     * @return \FFI\CData|null rd_kafka_topic_partition_t* - The object which can be used to fill in additionals fields.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a123ce30e08b31d4ff0fcf6ebe876173d
     */
    public static function rd_kafka_topic_partition_list_add(?\FFI\CData $rktparlist, ?string $topic, ?int $partition): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_topic_partition_list_add($rktparlist, $topic, $partition);
    }

    /**
     * <p>Add range of partitions from <code>start</code> to <code>stop</code> inclusive. </p>
     * @param \FFI\CData|null $rktparlist rd_kafka_topic_partition_list_t* - List to extend
     * @param string|null $topic const char* - Topic name (copied)
     * @param int|null $start int32_t - Start partition of range
     * @param int|null $stop int32_t - Last partition of range (inclusive)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a6365695de425e7866ddd0c59d704111b
     */
    public static function rd_kafka_topic_partition_list_add_range(?\FFI\CData $rktparlist, ?string $topic, ?int $start, ?int $stop): void
    {
        static::getFFI()->rd_kafka_topic_partition_list_add_range($rktparlist, $topic, $start, $stop);
    }

    /**
     * <p>Delete partition from list. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Any held indices to elems[] are unusable after this call returns 1. </dd></dl>
     * @param \FFI\CData|null $rktparlist rd_kafka_topic_partition_list_t* - List to modify
     * @param string|null $topic const char* - Topic name to match
     * @param int|null $partition int32_t - Partition to match
     * @return int|null int - 1 if partition was found (and removed), else 0.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a94a8195aa5f0195d020494bced858a97
     */
    public static function rd_kafka_topic_partition_list_del(?\FFI\CData $rktparlist, ?string $topic, ?int $partition): ?int
    {
        return static::getFFI()->rd_kafka_topic_partition_list_del($rktparlist, $topic, $partition);
    }

    /**
     * <p>Delete partition from list by elems[] index. </p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_topic_partition_list_del() </dd></dl>
     * @param \FFI\CData|null $rktparlist rd_kafka_topic_partition_list_t*
     * @param int|null $idx int
     * @return int|null int - 1 if partition was found (and removed), else 0.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a8476ebf3c2f54ddee53e0863feb85463
     */
    public static function rd_kafka_topic_partition_list_del_by_idx(?\FFI\CData $rktparlist, ?int $idx): ?int
    {
        return static::getFFI()->rd_kafka_topic_partition_list_del_by_idx($rktparlist, $idx);
    }

    /**
     * <p>Make a copy of an existing list. </p>
     * @param \FFI\CData|null $src rd_kafka_topic_partition_list_t* - ) - The existing list to copy.
     * @return \FFI\CData|null rd_kafka_topic_partition_list_t* - A new list fully populated to be identical to <code>src</code>
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a66fd3f8c00ffbd0ea740a638dd0a95f7
     */
    public static function rd_kafka_topic_partition_list_copy(?\FFI\CData $src): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_topic_partition_list_copy($src);
    }

    /**
     * <p>Set offset to <code>offset</code> for <code>topic</code> and <code>partition</code>. </p>
     * @param \FFI\CData|null $rktparlist rd_kafka_topic_partition_list_t*
     * @param string|null $topic const char*
     * @param int|null $partition int32_t
     * @param int|null $offset int64_t
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION if <code>partition</code> was not found in the list.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a102b340b901babb247d2c0a8580a094d
     */
    public static function rd_kafka_topic_partition_list_set_offset(?\FFI\CData $rktparlist, ?string $topic, ?int $partition, ?int $offset): int
    {
        return static::getFFI()->rd_kafka_topic_partition_list_set_offset($rktparlist, $topic, $partition, $offset);
    }

    /**
     * <p>Find element by <code>topic</code> and <code>partition</code>. </p>
     * @param \FFI\CData|null $rktparlist rd_kafka_topic_partition_list_t*
     * @param string|null $topic const char*
     * @param int|null $partition int32_t
     * @return \FFI\CData|null rd_kafka_topic_partition_t* - a pointer to the first matching element, or NULL if not found.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ab25d8e4e58c891bdc533471c210697fa
     */
    public static function rd_kafka_topic_partition_list_find(?\FFI\CData $rktparlist, ?string $topic, ?int $partition): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_topic_partition_list_find($rktparlist, $topic, $partition);
    }

    /**
     * <p>Sort list using comparator <code>cmp</code>. </p>
     * <p>If <code>cmp</code> is NULL the default comparator will be used that sorts by ascending topic name and partition. </p>
     * @param \FFI\CData|null $rktparlist rd_kafka_topic_partition_list_t*
     * @param \FFI\CData|\Closure $cmp int(*)(void*, void*, void*)
     * @param \FFI\CData|object|string|null $opaque void*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ab72ed92794eabf2e7ba1b7be9c94de1f
     */
    public static function rd_kafka_topic_partition_list_sort(?\FFI\CData $rktparlist, $cmp, $opaque): void
    {
        static::getFFI()->rd_kafka_topic_partition_list_sort($rktparlist, $cmp, $opaque);
    }

    /**
     * @param int|null $initial_count size_t
     * @return \FFI\CData|null rd_kafka_headers_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_headers_new(?int $initial_count): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_headers_new($initial_count);
    }

    /**
     * @param \FFI\CData|null $hdrs rd_kafka_headers_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_headers_destroy(?\FFI\CData $hdrs): void
    {
        static::getFFI()->rd_kafka_headers_destroy($hdrs);
    }

    /**
     * @param \FFI\CData|null $src rd_kafka_headers_t*
     * @return \FFI\CData|null rd_kafka_headers_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_headers_copy(?\FFI\CData $src): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_headers_copy($src);
    }

    /**
     * @param \FFI\CData|null $hdrs rd_kafka_headers_t*
     * @param string|null $name const char*
     * @param int|null $name_size ssize_t
     * @param \FFI\CData|object|string|null $value void*
     * @param int|null $value_size ssize_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_header_add(?\FFI\CData $hdrs, ?string $name, ?int $name_size, $value, ?int $value_size): int
    {
        return static::getFFI()->rd_kafka_header_add($hdrs, $name, $name_size, $value, $value_size);
    }

    /**
     * @param \FFI\CData|null $hdrs rd_kafka_headers_t*
     * @param string|null $name const char*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_header_remove(?\FFI\CData $hdrs, ?string $name): int
    {
        return static::getFFI()->rd_kafka_header_remove($hdrs, $name);
    }

    /**
     * @param \FFI\CData|null $hdrs rd_kafka_headers_t*
     * @param string|null $name const char*
     * @param \FFI\CData|object|string|null $valuep void**
     * @param \FFI\CData|null $sizep size_t*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_header_get_last(?\FFI\CData $hdrs, ?string $name, $valuep, ?\FFI\CData $sizep): int
    {
        return static::getFFI()->rd_kafka_header_get_last($hdrs, $name, $valuep, $sizep);
    }

    /**
     * @param \FFI\CData|null $hdrs rd_kafka_headers_t*
     * @param int|null $idx size_t
     * @param string|null $name const char*
     * @param \FFI\CData|object|string|null $valuep void**
     * @param \FFI\CData|null $sizep size_t*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_header_get(?\FFI\CData $hdrs, ?int $idx, ?string $name, $valuep, ?\FFI\CData $sizep): int
    {
        return static::getFFI()->rd_kafka_header_get($hdrs, $idx, $name, $valuep, $sizep);
    }

    /**
     * @param \FFI\CData|null $hdrs rd_kafka_headers_t*
     * @param int|null $idx size_t
     * @param \FFI\CData|null $namep char**
     * @param \FFI\CData|object|string|null $valuep void**
     * @param \FFI\CData|null $sizep size_t*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_header_get_all(?\FFI\CData $hdrs, ?int $idx, ?\FFI\CData $namep, $valuep, ?\FFI\CData $sizep): int
    {
        return static::getFFI()->rd_kafka_header_get_all($hdrs, $idx, $namep, $valuep, $sizep);
    }

    /**
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_message_destroy(?\FFI\CData $rkmessage): void
    {
        static::getFFI()->rd_kafka_message_destroy($rkmessage);
    }

    /**
     * <p>Returns the message timestamp for a consumed message. </p>
     * <p>The timestamp is the number of milliseconds since the epoch (UTC).</p>
     * <p><code>tstype</code> (if not NULL) is updated to indicate the type of timestamp.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Message timestamps require broker version 0.10.0 or later. </dd></dl>
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @param \FFI\CData|null $tstype rd_kafka_timestamp_type_t*
     * @return int|null int64_t - message timestamp, or -1 if not available.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a4371deba4afe6941cc5f9e80df5ca3e7
     */
    public static function rd_kafka_message_timestamp(?\FFI\CData $rkmessage, ?\FFI\CData $tstype): ?int
    {
        return static::getFFI()->rd_kafka_message_timestamp($rkmessage, $tstype);
    }

    /**
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @return int|null int64_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_message_latency(?\FFI\CData $rkmessage): ?int
    {
        return static::getFFI()->rd_kafka_message_latency($rkmessage);
    }

    /**
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @param \FFI\CData|null $hdrsp rd_kafka_headers_t**
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_message_headers(?\FFI\CData $rkmessage, ?\FFI\CData $hdrsp): int
    {
        return static::getFFI()->rd_kafka_message_headers($rkmessage, $hdrsp);
    }

    /**
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @param \FFI\CData|null $hdrsp rd_kafka_headers_t**
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_message_detach_headers(?\FFI\CData $rkmessage, ?\FFI\CData $hdrsp): int
    {
        return static::getFFI()->rd_kafka_message_detach_headers($rkmessage, $hdrsp);
    }

    /**
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @param \FFI\CData|null $hdrs rd_kafka_headers_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_message_set_headers(?\FFI\CData $rkmessage, ?\FFI\CData $hdrs): void
    {
        static::getFFI()->rd_kafka_message_set_headers($rkmessage, $hdrs);
    }

    /**
     * @param \FFI\CData|null $hdrs rd_kafka_headers_t*
     * @return int|null size_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_header_cnt(?\FFI\CData $hdrs): ?int
    {
        return static::getFFI()->rd_kafka_header_cnt($hdrs);
    }

    /**
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @return int rd_kafka_msg_status_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_message_status(?\FFI\CData $rkmessage): int
    {
        return static::getFFI()->rd_kafka_message_status($rkmessage);
    }

    /**
     * <p>Create configuration object. </p>
     * <p>When providing your own configuration to the <code>rd_kafka_*_new_*</code>() calls the rd_kafka_conf_t objects needs to be created with this function which will set up the defaults. I.e.: </p><div class="fragment"><div class="line"><span class="lineno">    1</span> rd_kafka_conf_t *myconf;</div>
     * <div class="line"><span class="lineno">    2</span> rd_kafka_conf_res_t res;</div>
     * <div class="line"><span class="lineno">    3</span> </div>
     * <div class="line"><span class="lineno">    4</span> myconf = rd_kafka_conf_new();</div>
     * <div class="line"><span class="lineno">    5</span> res = rd_kafka_conf_set(myconf, "socket.timeout.ms", "600",</div>
     * <div class="line"><span class="lineno">    6</span>                         errstr, sizeof(errstr));</div>
     * <div class="line"><span class="lineno">    7</span> if (res != RD_KAFKA_CONF_OK)</div>
     * <div class="line"><span class="lineno">    8</span>    die("%s\n", errstr);</div>
     * <div class="line"><span class="lineno">    9</span> </div>
     * <div class="line"><span class="lineno">   10</span> rk = rd_kafka_new(..., myconf);</div>
     * </div><!-- fragment --><p>Please see CONFIGURATION.md for the default settings or use rd_kafka_conf_properties_show() to provide the information at runtime.</p>
     * <p>The properties are identical to the Apache Kafka configuration properties whenever possible.</p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_conf_set(), rd_kafka_conf_destroy() </dd></dl>
     * @return \FFI\CData|null rd_kafka_conf_t* - ) - A new rd_kafka_conf_t object with defaults set.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#aa7459bd22e8cfa81aa8c2480a4a0304c
     */
    public static function rd_kafka_conf_new(): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_conf_new();
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_destroy(?\FFI\CData $conf): void
    {
        static::getFFI()->rd_kafka_conf_destroy($conf);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @return \FFI\CData|null rd_kafka_conf_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_dup(?\FFI\CData $conf): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_conf_dup($conf);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param int|null $filter_cnt size_t
     * @param \FFI\CData|null $filter char**
     * @return \FFI\CData|null rd_kafka_conf_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_dup_filter(?\FFI\CData $conf, ?int $filter_cnt, ?\FFI\CData $filter): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_conf_dup_filter($conf, $filter_cnt, $filter);
    }

    /**
     * <p>Sets a configuration property. </p>
     * <p><code>conf</code> must have been previously created with rd_kafka_conf_new().</p>
     * <p>Fallthrough: Topic-level configuration properties may be set using this interface in which case they are applied on the <code>default_topic_conf</code>. If no <code>default_topic_conf</code> has been set one will be created. Any sub-sequent rd_kafka_conf_set_default_topic_conf() calls will replace the current default topic configuration.</p>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param string|null $name const char*
     * @param string|null $value const char*
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_conf_res_t - <code>rd_kafka_conf_res_t</code> to indicate success or failure. In case of failure <code>errstr</code> is updated to contain a human readable error string.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#abb1b319278333e8cdee9442da7f135e8
     */
    public static function rd_kafka_conf_set(?\FFI\CData $conf, ?string $name, ?string $value, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_conf_set($conf, $name, $value, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param int|null $events int
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_set_events(?\FFI\CData $conf, ?int $events): void
    {
        static::getFFI()->rd_kafka_conf_set_events($conf, $events);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $event_cb void(*)(rd_kafka_t*, rd_kafka_event_t*, void*)
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_set_background_event_cb(?\FFI\CData $conf, $event_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_background_event_cb($conf, $event_cb);
    }

    /**
     * <dl class="deprecated"><dt><b>Deprecated:</b></dt><dd>See rd_kafka_conf_set_dr_msg_cb() </dd></dl>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $dr_cb void(*)(rd_kafka_t*, void*, size_t, rd_kafka_resp_err_t, void*, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a075b15c4141784fdc271de217005a41f
     */
    public static function rd_kafka_conf_set_dr_cb(?\FFI\CData $conf, $dr_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_dr_cb($conf, $dr_cb);
    }

    /**
     * <p><b>Producer:</b> Set delivery report callback in provided <code>conf</code> object. </p>
     * <p>The delivery report callback will be called once for each message accepted by rd_kafka_produce() (et.al) with <code>err</code> set to indicate the result of the produce request.</p>
     * <p>The callback is called when a message is succesfully produced or if librdkafka encountered a permanent failure, or the retry counter for temporary errors has been exhausted.</p>
     * <p>An application must call rd_kafka_poll() at regular intervals to serve queued delivery report callbacks. </p>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $dr_msg_cb void(*)(rd_kafka_t*, rd_kafka_message_t*, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ac1c9946aee26e10de2661fcf2242ea8a
     */
    public static function rd_kafka_conf_set_dr_msg_cb(?\FFI\CData $conf, $dr_msg_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_dr_msg_cb($conf, $dr_msg_cb);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $consume_cb void(*)(rd_kafka_message_t*, void*)
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_set_consume_cb(?\FFI\CData $conf, $consume_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_consume_cb($conf, $consume_cb);
    }

    /**
     * <p><b>Consumer:</b> Set rebalance callback for use with coordinated consumer group balancing. </p>
     * <p>The <code>err</code> field is set to either RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS or RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS and 'partitions' contains the full partition set that was either assigned or revoked.</p>
     * <p>Registering a <code>rebalance_cb</code> turns off librdkafka's automatic partition assignment/revocation and instead delegates that responsibility to the application's <code>rebalance_cb</code>.</p>
     * <p>The rebalance callback is responsible for updating librdkafka's assignment set based on the two events: RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS and RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS but should also be able to handle arbitrary rebalancing failures where <code>err</code> is neither of those. </p><dl class="section remark"><dt>Remarks</dt><dd>In this latter case (arbitrary error), the application must call rd_kafka_assign(rk, NULL) to synchronize state.</dd></dl><p>Without a rebalance callback this is done automatically by librdkafka but registering a rebalance callback gives the application flexibility in performing other operations along with the assinging/revocation, such as fetching offsets from an alternate location (on assign) or manually committing offsets (on revoke).</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>The <code>partitions</code> list is destroyed by librdkafka on return return from the rebalance_cb and must not be freed or saved by the application.</dd></dl><p>The following example shows the application's responsibilities: </p><div class="fragment"><div class="line"><span class="lineno">    1</span> static void rebalance_cb (rd_kafka_t *rk, rd_kafka_resp_err_t err,</div>
     * <div class="line"><span class="lineno">    2</span>                           rd_kafka_topic_partition_list_t *partitions,</div>
     * <div class="line"><span class="lineno">    3</span>                           void *opaque) {</div>
     * <div class="line"><span class="lineno">    4</span> </div>
     * <div class="line"><span class="lineno">    5</span>     switch (err)</div>
     * <div class="line"><span class="lineno">    6</span>     {</div>
     * <div class="line"><span class="lineno">    7</span>       case RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS:</div>
     * <div class="line"><span class="lineno">    8</span>          // application may load offets from arbitrary external</div>
     * <div class="line"><span class="lineno">    9</span>          // storage here and update \p partitions</div>
     * <div class="line"><span class="lineno">   10</span> </div>
     * <div class="line"><span class="lineno">   11</span>          rd_kafka_assign(rk, partitions);</div>
     * <div class="line"><span class="lineno">   12</span>          break;</div>
     * <div class="line"><span class="lineno">   13</span> </div>
     * <div class="line"><span class="lineno">   14</span>       case RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS:</div>
     * <div class="line"><span class="lineno">   15</span>          if (manual_commits) // Optional explicit manual commit</div>
     * <div class="line"><span class="lineno">   16</span>              rd_kafka_commit(rk, partitions, 0); // sync commit</div>
     * <div class="line"><span class="lineno">   17</span> </div>
     * <div class="line"><span class="lineno">   18</span>          rd_kafka_assign(rk, NULL);</div>
     * <div class="line"><span class="lineno">   19</span>          break;</div>
     * <div class="line"><span class="lineno">   20</span> </div>
     * <div class="line"><span class="lineno">   21</span>       default:</div>
     * <div class="line"><span class="lineno">   22</span>          handle_unlikely_error(err);</div>
     * <div class="line"><span class="lineno">   23</span>          rd_kafka_assign(rk, NULL); // sync state</div>
     * <div class="line"><span class="lineno">   24</span>          break;</div>
     * <div class="line"><span class="lineno">   25</span>      }</div>
     * <div class="line"><span class="lineno">   26</span> }</div>
     * </div><!-- fragment -->
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $rebalance_cb void(*)(rd_kafka_t*, rd_kafka_resp_err_t, rd_kafka_topic_partition_list_t*, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a10db731dc1a295bd9884e4f8cb199311
     */
    public static function rd_kafka_conf_set_rebalance_cb(?\FFI\CData $conf, $rebalance_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_rebalance_cb($conf, $rebalance_cb);
    }

    /**
     * <p><b>Consumer:</b> Set offset commit callback for use with consumer groups. </p>
     * <p>The results of automatic or manual offset commits will be scheduled for this callback and is served by rd_kafka_consumer_poll().</p>
     * <p>If no partitions had valid offsets to commit this callback will be called with <code>err</code> == RD_KAFKA_RESP_ERR__NO_OFFSET which is not to be considered an error.</p>
     * <p>The <code>offsets</code> list contains per-partition information:</p><ul><li><code>offset:</code> committed offset (attempted)</li>
     * <li><code>err:</code> commit error </li>
     * </ul>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $offset_commit_cb void(*)(rd_kafka_t*, rd_kafka_resp_err_t, rd_kafka_topic_partition_list_t*, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a1ab8bb9e8d8cdd5906f9e060b506f2eb
     */
    public static function rd_kafka_conf_set_offset_commit_cb(?\FFI\CData $conf, $offset_commit_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_offset_commit_cb($conf, $offset_commit_cb);
    }

    /**
     * <p>Set error callback in provided conf object. </p>
     * <p>The error callback is used by librdkafka to signal critical errors back to the application.</p>
     * <p>If no <code>error_cb</code> is registered then the errors will be logged instead. </p>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $error_cb void(*)(rd_kafka_t*, int, const char*, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ace721ef3b7c22d0c111ec747ef039a90
     */
    public static function rd_kafka_conf_set_error_cb(?\FFI\CData $conf, $error_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_error_cb($conf, $error_cb);
    }

    /**
     * <p>Set throttle callback. </p>
     * <p>The throttle callback is used to forward broker throttle times to the application for Produce and Fetch (consume) requests.</p>
     * <p>Callbacks are triggered whenever a non-zero throttle time is returned by the broker, or when the throttle time drops back to zero.</p>
     * <p>An application must call rd_kafka_poll() or rd_kafka_consumer_poll() at regular intervals to serve queued callbacks.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Requires broker version 0.9.0 or later. </dd></dl>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $throttle_cb void(*)(rd_kafka_t*, const char*, int32_t, int, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a04160826ad039d42c10edec456163fa7
     */
    public static function rd_kafka_conf_set_throttle_cb(?\FFI\CData $conf, $throttle_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_throttle_cb($conf, $throttle_cb);
    }

    /**
     * <p>Set logger callback. </p>
     * <p>The default is to print to stderr, but a syslog logger is also available, see rd_kafka_log_print and rd_kafka_log_syslog for the builtin alternatives. Alternatively the application may provide its own logger callback. Or pass <code>func</code> as NULL to disable logging.</p>
     * <p>This is the configuration alternative to the deprecated rd_kafka_set_logger()</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>The log_cb will be called spontaneously from librdkafka's internal threads unless logs have been forwarded to a poll queue through <code>rd_kafka_set_log_queue()</code>. An application MUST NOT call any librdkafka APIs or do any prolonged work in a non-forwarded <code>log_cb</code>. </dd></dl>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $log_cb void(*)(rd_kafka_t*, int, const char*, const char*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a06ade2ca41f32eb82c6f7e3d4acbe19f
     */
    public static function rd_kafka_conf_set_log_cb(?\FFI\CData $conf, $log_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_log_cb($conf, $log_cb);
    }

    /**
     * <p>Set statistics callback in provided conf object. </p>
     * <p>The statistics callback is triggered from rd_kafka_poll() every <code>statistics.interval.ms</code> (needs to be configured separately). Function arguments:</p><ul><li><code>rk</code> - Kafka handle</li>
     * <li><code>json</code> - String containing the statistics data in JSON format</li>
     * <li><code>json_len</code> - Length of <code>json</code> string.</li>
     * <li><code>opaque</code> - Application-provided opaque.</li>
     * </ul><p>If the application wishes to hold on to the <code>json</code> pointer and free it at a later time it must return 1 from the <code>stats_cb</code>. If the application returns 0 from the <code>stats_cb</code> then librdkafka will immediately free the <code>json</code> pointer. </p>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $stats_cb int(*)(rd_kafka_t*, char*, size_t, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a597d00432e3ca22174d18e7e348fb766
     */
    public static function rd_kafka_conf_set_stats_cb(?\FFI\CData $conf, $stats_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_stats_cb($conf, $stats_cb);
    }

    /**
     * <p>Set socket callback. </p>
     * <p>The socket callback is responsible for opening a socket according to the supplied <code>domain</code>, <code>type</code> and <code>protocol</code>. The socket shall be created with <code>CLOEXEC</code> set in a racefree fashion, if possible.</p>
     * <p>Default:</p><ul><li>on linux: racefree CLOEXEC</li>
     * <li>others : non-racefree CLOEXEC</li>
     * </ul><dl class="section remark"><dt>Remarks</dt><dd>The callback will be called from an internal librdkafka thread. </dd></dl>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $socket_cb int(*)(int, int, int, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a0467a6c20d5af69a29a63b530962ecbf
     */
    public static function rd_kafka_conf_set_socket_cb(?\FFI\CData $conf, $socket_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_socket_cb($conf, $socket_cb);
    }

    /**
     * <p>Set connect callback. </p>
     * <p>The connect callback is responsible for connecting socket <code>sockfd</code> to peer address <code>addr</code>. The <code>id</code> field contains the broker identifier.</p>
     * <p><code>connect_cb</code> shall return 0 on success (socket connected) or an error number (errno) on error.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>The callback will be called from an internal librdkafka thread. </dd></dl>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $connect_cb int(*)(int, struct sockaddr*, int, const char*, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a53dd1b77019324170d0168617fdaf040
     */
    public static function rd_kafka_conf_set_connect_cb(?\FFI\CData $conf, $connect_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_connect_cb($conf, $connect_cb);
    }

    /**
     * <p>Set close socket callback. </p>
     * <p>Close a socket (optionally opened with socket_cb()).</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>The callback will be called from an internal librdkafka thread. </dd></dl>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $closesocket_cb int(*)(int, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ab55c7ddc46a354e3f57b5b209e5ec3c7
     */
    public static function rd_kafka_conf_set_closesocket_cb(?\FFI\CData $conf, $closesocket_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_closesocket_cb($conf, $closesocket_cb);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|object|string|null $opaque void*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_set_opaque(?\FFI\CData $conf, $opaque): void
    {
        static::getFFI()->rd_kafka_conf_set_opaque($conf, $opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return \FFI\CData|object|string|null void*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_opaque(?\FFI\CData $rk)
    {
        return static::getFFI()->rd_kafka_opaque($rk);
    }

    /**
     * <p>Sets the default topic configuration to use for automatically subscribed topics (e.g., through pattern-matched topics). The topic config object is not usable after this call. </p>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|null $tconf rd_kafka_topic_conf_t*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a138aa4881c8703dd6b69f22ddc454f63
     */
    public static function rd_kafka_conf_set_default_topic_conf(?\FFI\CData $conf, ?\FFI\CData $tconf): void
    {
        static::getFFI()->rd_kafka_conf_set_default_topic_conf($conf, $tconf);
    }

    /**
     * <p>Retrieve configuration value for property <code>name</code>. </p>
     * <p>If <code>dest</code> is non-NULL the value will be written to <code>dest</code> with at most <code>dest_size</code>.</p>
     * <p><code>*dest_size</code> is updated to the full length of the value, thus if <code>*dest_size</code> initially is smaller than the full length the application may reallocate <code>dest</code> to fit the returned <code>*dest_size</code> and try again.</p>
     * <p>If <code>dest</code> is NULL only the full length of the value is returned.</p>
     * <p>Fallthrough: Topic-level configuration properties from the <code>default_topic_conf</code> may be retrieved using this interface.</p>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param string|null $name const char*
     * @param \FFI\CData|null $dest char*
     * @param \FFI\CData|null $dest_size size_t*
     * @return int rd_kafka_conf_res_t - <code>RD_KAFKA_CONF_OK</code> if the property name matched, else <code>RD_KAFKA_CONF_UNKNOWN</code>.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#abe9f0f77e9145eb1a62c3258ac495b97
     */
    public static function rd_kafka_conf_get(?\FFI\CData $conf, ?string $name, ?\FFI\CData $dest, ?\FFI\CData $dest_size): int
    {
        return static::getFFI()->rd_kafka_conf_get($conf, $name, $dest, $dest_size);
    }

    /**
     * <p>Retrieve topic configuration value for property <code>name</code>. </p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_conf_get() </dd></dl>
     * @param \FFI\CData|null $conf rd_kafka_topic_conf_t*
     * @param string|null $name const char*
     * @param \FFI\CData|null $dest char*
     * @param \FFI\CData|null $dest_size size_t*
     * @return int rd_kafka_conf_res_t
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a56939e7f77106b9e810d59289443e25d
     */
    public static function rd_kafka_topic_conf_get(?\FFI\CData $conf, ?string $name, ?\FFI\CData $dest, ?\FFI\CData $dest_size): int
    {
        return static::getFFI()->rd_kafka_topic_conf_get($conf, $name, $dest, $dest_size);
    }

    /**
     * <p>Dump the configuration properties and values of <code>conf</code> to an array with "key", "value" pairs. </p>
     * <p>The number of entries in the array is returned in <code>*cntp</code>.</p>
     * <p>The dump must be freed with <code>rd_kafka_conf_dump_free()</code>. </p>
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|null $cntp size_t*
     * @return \FFI\CData|null const char**
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a6eba851c2af748de6921d708b47dc94c
     */
    public static function rd_kafka_conf_dump(?\FFI\CData $conf, ?\FFI\CData $cntp): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_conf_dump($conf, $cntp);
    }

    /**
     * <p>Dump the topic configuration properties and values of <code>conf</code> to an array with "key", "value" pairs. </p>
     * <p>The number of entries in the array is returned in <code>*cntp</code>.</p>
     * <p>The dump must be freed with <code>rd_kafka_conf_dump_free()</code>. </p>
     * @param \FFI\CData|null $conf rd_kafka_topic_conf_t*
     * @param \FFI\CData|null $cntp size_t*
     * @return \FFI\CData|null const char**
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a40a7a88bd5ac81b21c45d1fdd4d9e696
     */
    public static function rd_kafka_topic_conf_dump(?\FFI\CData $conf, ?\FFI\CData $cntp): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_topic_conf_dump($conf, $cntp);
    }

    /**
     * @param \FFI\CData|null $arr char**
     * @param int|null $cnt size_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_dump_free(?\FFI\CData $arr, ?int $cnt): void
    {
        static::getFFI()->rd_kafka_conf_dump_free($arr, $cnt);
    }

    /**
     * @param \FFI\CData|null $fp FILE*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_properties_show(?\FFI\CData $fp): void
    {
        static::getFFI()->rd_kafka_conf_properties_show($fp);
    }

    /**
     * <p>Create topic configuration object. </p>
     * <dl class="section see"><dt>See also</dt><dd>Same semantics as for rd_kafka_conf_new(). </dd></dl>
     * @return \FFI\CData|null rd_kafka_topic_conf_t* - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a1a7032f87e7d868b80e38d0fd0ad119e
     */
    public static function rd_kafka_topic_conf_new(): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_topic_conf_new();
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_topic_conf_t*
     * @return \FFI\CData|null rd_kafka_topic_conf_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_conf_dup(?\FFI\CData $conf): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_topic_conf_dup($conf);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return \FFI\CData|null rd_kafka_topic_conf_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_default_topic_conf_dup(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_default_topic_conf_dup($rk);
    }

    /**
     * @param \FFI\CData|null $topic_conf rd_kafka_topic_conf_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_conf_destroy(?\FFI\CData $topic_conf): void
    {
        static::getFFI()->rd_kafka_topic_conf_destroy($topic_conf);
    }

    /**
     * <p>Sets a single rd_kafka_topic_conf_t value by property name. </p>
     * <p><code>topic_conf</code> should have been previously set up with <code>rd_kafka_topic_conf_new()</code>.</p>
     * @param \FFI\CData|null $conf rd_kafka_topic_conf_t*
     * @param string|null $name const char*
     * @param string|null $value const char*
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_conf_res_t - rd_kafka_conf_res_t to indicate success or failure.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ac91b47f7733b324bf4159427e90ccd01
     */
    public static function rd_kafka_topic_conf_set(?\FFI\CData $conf, ?string $name, ?string $value, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_topic_conf_set($conf, $name, $value, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_topic_conf_t*
     * @param \FFI\CData|object|string|null $opaque void*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_conf_set_opaque(?\FFI\CData $conf, $opaque): void
    {
        static::getFFI()->rd_kafka_topic_conf_set_opaque($conf, $opaque);
    }

    /**
     * <p><b>Producer:</b> Set partitioner callback in provided topic conf object. </p>
     * <p>The partitioner may be called in any thread at any time, it may be called multiple times for the same message/key.</p>
     * <p>Partitioner function constraints:</p><ul><li>MUST NOT call any rd_kafka_*() functions except: rd_kafka_topic_partition_available()</li>
     * <li>MUST NOT block or execute for prolonged periods of time.</li>
     * <li>MUST return a value between 0 and partition_cnt-1, or the special <code>RD_KAFKA_PARTITION_UA</code> value if partitioning could not be performed. </li>
     * </ul>
     * @param \FFI\CData|null $topic_conf rd_kafka_topic_conf_t*
     * @param \FFI\CData|\Closure $partitioner int32_t(*)(rd_kafka_topic_t*, void*, size_t, int32_t, void*, void*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#abfc790b5e36c56ea6d79fdc32c57becf
     */
    public static function rd_kafka_topic_conf_set_partitioner_cb(?\FFI\CData $topic_conf, $partitioner): void
    {
        static::getFFI()->rd_kafka_topic_conf_set_partitioner_cb($topic_conf, $partitioner);
    }

    /**
     * @param \FFI\CData|null $topic_conf rd_kafka_topic_conf_t*
     * @param \FFI\CData|\Closure $msg_order_cmp int(*)(rd_kafka_message_t*, rd_kafka_message_t*)
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_conf_set_msg_order_cmp(?\FFI\CData $topic_conf, $msg_order_cmp): void
    {
        static::getFFI()->rd_kafka_topic_conf_set_msg_order_cmp($topic_conf, $msg_order_cmp);
    }

    /**
     * <p>Check if partition is available (has a leader broker). </p>
     * <dl class="section warning"><dt>Warning</dt><dd>This function must only be called from inside a partitioner function </dd></dl>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @return int|null int - 1 if the partition is available, else 0.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ad24c6cc7f37271e292f8105c64d77758
     */
    public static function rd_kafka_topic_partition_available(?\FFI\CData $rkt, ?int $partition): ?int
    {
        return static::getFFI()->rd_kafka_topic_partition_available($rkt, $partition);
    }

    /**
     * <p>Random partitioner. </p>
     * <p>Will try not to return unavailable partitions.</p>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param \FFI\CData|object|string|null $key void*
     * @param int|null $keylen size_t
     * @param int|null $partition_cnt int32_t
     * @param \FFI\CData|object|string|null $opaque void*
     * @param \FFI\CData|object|string|null $msg_opaque void*
     * @return int|null int32_t - a random partition between 0 and <code>partition_cnt</code> - 1.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ae8690da243d6d22f52cf8a6f0e90d7e8
     */
    public static function rd_kafka_msg_partitioner_random(?\FFI\CData $rkt, $key, ?int $keylen, ?int $partition_cnt, $opaque, $msg_opaque): ?int
    {
        return static::getFFI()->rd_kafka_msg_partitioner_random($rkt, $key, $keylen, $partition_cnt, $opaque, $msg_opaque);
    }

    /**
     * <p>Consistent partitioner. </p>
     * <p>Uses consistent hashing to map identical keys onto identical partitions.</p>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param \FFI\CData|object|string|null $key void*
     * @param int|null $keylen size_t
     * @param int|null $partition_cnt int32_t
     * @param \FFI\CData|object|string|null $opaque void*
     * @param \FFI\CData|object|string|null $msg_opaque void*
     * @return int|null int32_t - a "random" partition between 0 and <code>partition_cnt</code> - 1 based on the CRC value of the key
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a09edd9204e8fb28dae7a8b000d4492ef
     */
    public static function rd_kafka_msg_partitioner_consistent(?\FFI\CData $rkt, $key, ?int $keylen, ?int $partition_cnt, $opaque, $msg_opaque): ?int
    {
        return static::getFFI()->rd_kafka_msg_partitioner_consistent($rkt, $key, $keylen, $partition_cnt, $opaque, $msg_opaque);
    }

    /**
     * <p>Consistent-Random partitioner. </p>
     * <p>This is the default partitioner. Uses consistent hashing to map identical keys onto identical partitions, and messages without keys will be assigned via the random partitioner.</p>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param \FFI\CData|object|string|null $key void*
     * @param int|null $keylen size_t
     * @param int|null $partition_cnt int32_t
     * @param \FFI\CData|object|string|null $opaque void*
     * @param \FFI\CData|object|string|null $msg_opaque void*
     * @return int|null int32_t - a "random" partition between 0 and <code>partition_cnt</code> - 1 based on the CRC value of the key (if provided)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a2b79580e110b06ea5434fb71abc0b4eb
     */
    public static function rd_kafka_msg_partitioner_consistent_random(?\FFI\CData $rkt, $key, ?int $keylen, ?int $partition_cnt, $opaque, $msg_opaque): ?int
    {
        return static::getFFI()->rd_kafka_msg_partitioner_consistent_random($rkt, $key, $keylen, $partition_cnt, $opaque, $msg_opaque);
    }

    /**
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param \FFI\CData|object|string|null $key void*
     * @param int|null $keylen size_t
     * @param int|null $partition_cnt int32_t
     * @param \FFI\CData|object|string|null $rkt_opaque void*
     * @param \FFI\CData|object|string|null $msg_opaque void*
     * @return int|null int32_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_msg_partitioner_murmur2(?\FFI\CData $rkt, $key, ?int $keylen, ?int $partition_cnt, $rkt_opaque, $msg_opaque): ?int
    {
        return static::getFFI()->rd_kafka_msg_partitioner_murmur2($rkt, $key, $keylen, $partition_cnt, $rkt_opaque, $msg_opaque);
    }

    /**
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param \FFI\CData|object|string|null $key void*
     * @param int|null $keylen size_t
     * @param int|null $partition_cnt int32_t
     * @param \FFI\CData|object|string|null $rkt_opaque void*
     * @param \FFI\CData|object|string|null $msg_opaque void*
     * @return int|null int32_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_msg_partitioner_murmur2_random(?\FFI\CData $rkt, $key, ?int $keylen, ?int $partition_cnt, $rkt_opaque, $msg_opaque): ?int
    {
        return static::getFFI()->rd_kafka_msg_partitioner_murmur2_random($rkt, $key, $keylen, $partition_cnt, $rkt_opaque, $msg_opaque);
    }

    /**
     * <p>Creates a new Kafka handle and starts its operation according to the specified <code>type</code> (<code>RD_KAFKA_CONSUMER</code> or <code>RD_KAFKA_PRODUCER</code>). </p>
     * <p><code>conf</code> is an optional struct created with <code>rd_kafka_conf_new()</code> that will be used instead of the default configuration. The <code>conf</code> object is freed by this function on success and must not be used or destroyed by the application sub-sequently. See <code>rd_kafka_conf_set()</code> et.al for more information.</p>
     * <p><code>errstr</code> must be a pointer to memory of at least size <code>errstr_size</code> where <code>rd_kafka_new()</code> may write a human readable error message in case the creation of a new handle fails. In which case the function returns NULL.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd><b>RD_KAFKA_CONSUMER:</b> When a new <code>RD_KAFKA_CONSUMER</code> rd_kafka_t handle is created it may either operate in the legacy simple consumer mode using the rd_kafka_consume_start() interface, or the High-level KafkaConsumer API. </dd>
     * <dd>
     * An application must only use one of these groups of APIs on a given rd_kafka_t RD_KAFKA_CONSUMER handle.</dd></dl><dl class="section see"><dt>See also</dt><dd>To destroy the Kafka handle, use rd_kafka_destroy(). </dd></dl>
     * @param int $type rd_kafka_type_t
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return \FFI\CData|null rd_kafka_t* - The Kafka handle on success or NULL on error (see <code>errstr</code>)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a63d5cd86ab1f77772b2be170e1c09c24
     */
    public static function rd_kafka_new(int $type, ?\FFI\CData $conf, ?\FFI\CData $errstr, ?int $errstr_size): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_new($type, $conf, $errstr, $errstr_size);
    }

    /**
     * <p>Destroy Kafka handle. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>This is a blocking operation. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t* - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ac052e92621dcaa3a336dbf826e0d7794
     */
    public static function rd_kafka_destroy(?\FFI\CData $rk): void
    {
        static::getFFI()->rd_kafka_destroy($rk);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $flags int
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_destroy_flags(?\FFI\CData $rk, ?int $flags): void
    {
        static::getFFI()->rd_kafka_destroy_flags($rk, $flags);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_name(?\FFI\CData $rk): ?string
    {
        return static::getFFI()->rd_kafka_name($rk);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return int rd_kafka_type_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_type(?\FFI\CData $rk): int
    {
        return static::getFFI()->rd_kafka_type($rk);
    }

    /**
     * <p>Returns this client's broker-assigned group member id. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>This currently requires the high-level KafkaConsumer</dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t* - )
     * @return \FFI\CData|null char* - An allocated string containing the current broker-assigned group member id, or NULL if not available. The application must free the string with <code>free()</code> or rd_kafka_mem_free()
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a856d7ecba1aa64e5c89ac92b445cdda6
     */
    public static function rd_kafka_memberid(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_memberid($rk);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $timeout_ms int
     * @return \FFI\CData|null char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_clusterid(?\FFI\CData $rk, ?int $timeout_ms): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_clusterid($rk, $timeout_ms);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $timeout_ms int
     * @return int|null int32_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_controllerid(?\FFI\CData $rk, ?int $timeout_ms): ?int
    {
        return static::getFFI()->rd_kafka_controllerid($rk, $timeout_ms);
    }

    /**
     * <p>Creates a new topic handle for topic named <code>topic</code>. </p>
     * <p><code>conf</code> is an optional configuration for the topic created with <code>rd_kafka_topic_conf_new()</code> that will be used instead of the default topic configuration. The <code>conf</code> object is freed by this function and must not be used or destroyed by the application sub-sequently. See <code>rd_kafka_topic_conf_set()</code> et.al for more information.</p>
     * <p>Topic handles are refcounted internally and calling rd_kafka_topic_new() again with the same topic name will return the previous topic handle without updating the original handle's configuration. Applications must eventually call rd_kafka_topic_destroy() for each succesfull call to rd_kafka_topic_new() to clear up resources.</p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_topic_destroy() </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $topic const char*
     * @param \FFI\CData|null $conf rd_kafka_topic_conf_t*
     * @return \FFI\CData|null rd_kafka_topic_t* - the new topic handle or NULL on error (use rd_kafka_errno2err() to convert system <code>errno</code> to an rd_kafka_resp_err_t error code.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ab1dcba74a35e8f3bfe3270ff600581d8
     */
    public static function rd_kafka_topic_new(?\FFI\CData $rk, ?string $topic, ?\FFI\CData $conf): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_topic_new($rk, $topic, $conf);
    }

    /**
     * <p>Loose application's topic handle refcount as previously created with <code>rd_kafka_topic_new()</code>. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Since topic objects are refcounted (both internally and for the app) the topic object might not actually be destroyed by this call, but the application must consider the object destroyed. </dd></dl>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t* - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a91f46cd29d4f9abacd3ee3633c01d8ff
     */
    public static function rd_kafka_topic_destroy(?\FFI\CData $rkt): void
    {
        static::getFFI()->rd_kafka_topic_destroy($rkt);
    }

    /**
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_name(?\FFI\CData $rkt): ?string
    {
        return static::getFFI()->rd_kafka_topic_name($rkt);
    }

    /**
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @return \FFI\CData|object|string|null void*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_opaque(?\FFI\CData $rkt)
    {
        return static::getFFI()->rd_kafka_topic_opaque($rkt);
    }

    /**
     * <p>Polls the provided kafka handle for events. </p>
     * <p>Events will cause application provided callbacks to be called.</p>
     * <p>The <code>timeout_ms</code> argument specifies the maximum amount of time (in milliseconds) that the call will block waiting for events. For non-blocking calls, provide 0 as <code>timeout_ms</code>. To wait indefinately for an event, provide -1.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>An application should make sure to call poll() at regular intervals to serve any queued callbacks waiting to be called.</dd></dl><p>Events:</p><ul><li>delivery report callbacks (if dr_cb/dr_msg_cb is configured) [producer]</li>
     * <li>error callbacks (rd_kafka_conf_set_error_cb()) [all]</li>
     * <li>stats callbacks (rd_kafka_conf_set_stats_cb()) [all]</li>
     * <li>throttle callbacks (rd_kafka_conf_set_throttle_cb()) [all]</li>
     * </ul>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $timeout_ms int
     * @return int|null int - the number of events served.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ad50c431e3a29d14da534db49bd0682a4
     */
    public static function rd_kafka_poll(?\FFI\CData $rk, ?int $timeout_ms): ?int
    {
        return static::getFFI()->rd_kafka_poll($rk, $timeout_ms);
    }

    /**
     * <p>Cancels the current callback dispatcher (rd_kafka_poll(), rd_kafka_consume_callback(), etc). </p>
     * <p>A callback may use this to force an immediate return to the calling code (caller of e.g. rd_kafka_poll()) without processing any further events.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>This function MUST ONLY be called from within a librdkafka callback. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t* - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a111628df6c84716c4b550f8509ac6a6d
     */
    public static function rd_kafka_yield(?\FFI\CData $rk): void
    {
        static::getFFI()->rd_kafka_yield($rk);
    }

    /**
     * <p>Pause producing or consumption for the provided list of partitions. </p>
     * <p>Success or error is returned per-partition <code>err</code> in the <code>partitions</code> list.</p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $partitions rd_kafka_topic_partition_list_t*
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a293cb2aac290c157702d3b82f5c14fce
     */
    public static function rd_kafka_pause_partitions(?\FFI\CData $rk, ?\FFI\CData $partitions): int
    {
        return static::getFFI()->rd_kafka_pause_partitions($rk, $partitions);
    }

    /**
     * <p>Resume producing consumption for the provided list of partitions. </p>
     * <p>Success or error is returned per-partition <code>err</code> in the <code>partitions</code> list.</p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $partitions rd_kafka_topic_partition_list_t*
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ad05819f26887a916ad2047d96a7b4bf2
     */
    public static function rd_kafka_resume_partitions(?\FFI\CData $rk, ?\FFI\CData $partitions): int
    {
        return static::getFFI()->rd_kafka_resume_partitions($rk, $partitions);
    }

    /**
     * <p>Query broker for low (oldest/beginning) and high (newest/end) offsets for partition. </p>
     * <p>Offsets are returned in <code>*low</code> and <code>*high</code> respectively.</p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $topic const char*
     * @param int|null $partition int32_t
     * @param \FFI\CData|null $low int64_t*
     * @param \FFI\CData|null $high int64_t*
     * @param int|null $timeout_ms int
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR on success or an error code on failure.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a4550ff7d014f08406666124573f70495
     */
    public static function rd_kafka_query_watermark_offsets(?\FFI\CData $rk, ?string $topic, ?int $partition, ?\FFI\CData $low, ?\FFI\CData $high, ?int $timeout_ms): int
    {
        return static::getFFI()->rd_kafka_query_watermark_offsets($rk, $topic, $partition, $low, $high, $timeout_ms);
    }

    /**
     * <p>Get last known low (oldest/beginning) and high (newest/end) offsets for partition. </p>
     * <p>The low offset is updated periodically (if statistics.interval.ms is set) while the high offset is updated on each fetched message set from the broker.</p>
     * <p>If there is no cached offset (either low or high, or both) then RD_KAFKA_OFFSET_INVALID will be returned for the respective offset.</p>
     * <p>Offsets are returned in <code>*low</code> and <code>*high</code> respectively.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Shall only be used with an active consumer instance. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $topic const char*
     * @param int|null $partition int32_t
     * @param \FFI\CData|null $low int64_t*
     * @param \FFI\CData|null $high int64_t*
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR on success or an error code on failure.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ad1d338cebde98a76050e61301f631d82
     */
    public static function rd_kafka_get_watermark_offsets(?\FFI\CData $rk, ?string $topic, ?int $partition, ?\FFI\CData $low, ?\FFI\CData $high): int
    {
        return static::getFFI()->rd_kafka_get_watermark_offsets($rk, $topic, $partition, $low, $high);
    }

    /**
     * <p>Look up the offsets for the given partitions by timestamp. </p>
     * <p>The returned offset for each partition is the earliest offset whose timestamp is greater than or equal to the given timestamp in the corresponding partition.</p>
     * <p>The timestamps to query are represented as <code>offset</code> in <code>offsets</code> on input, and <code>offset</code> will contain the offset on output.</p>
     * <p>The function will block for at most <code>timeout_ms</code> milliseconds.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Duplicate Topic+Partitions are not supported. </dd>
     * <dd>
     * Per-partition errors may be returned in <code>rd_kafka_topic_partition_t.err</code> </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $offsets rd_kafka_topic_partition_list_t*
     * @param int|null $timeout_ms int
     * @return int rd_kafka_resp_err_t - an error code for general errors, else RD_KAFKA_RESP_ERR_NO_ERROR in which case per-partition errors might be set.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ae308aaf534807cfd4c71e423fc214929
     */
    public static function rd_kafka_offsets_for_times(?\FFI\CData $rk, ?\FFI\CData $offsets, ?int $timeout_ms): int
    {
        return static::getFFI()->rd_kafka_offsets_for_times($rk, $offsets, $timeout_ms);
    }

    /**
     * <p>Free pointer returned by librdkafka. </p>
     * <p>This is typically an abstraction for the free(3) call and makes sure the application can use the same memory allocator as librdkafka for freeing pointers returned by librdkafka.</p>
     * <p>In standard setups it is usually not necessary to use this interface rather than the free(3) functione.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>rd_kafka_mem_free() must only be used for pointers returned by APIs that explicitly mention using this function for freeing. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|object|string|null $ptr void*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a50178b3d3266c9eeb0b5981377833572
     */
    public static function rd_kafka_mem_free(?\FFI\CData $rk, $ptr): void
    {
        static::getFFI()->rd_kafka_mem_free($rk, $ptr);
    }

    /**
     * <p>Create a new message queue. </p>
     * <p>See rd_kafka_consume_start_queue(), rd_kafka_consume_queue(), et.al. </p>
     * @param \FFI\CData|null $rk rd_kafka_t* - )
     * @return \FFI\CData|null rd_kafka_queue_t*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a2b59178eb7e88d40510a89f3f2d98b44
     */
    public static function rd_kafka_queue_new(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_queue_new($rk);
    }

    /**
     * <p>Destroy a queue, purging all of its enqueued messages. </p>
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t* - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a9421b3d450f1489cf46f68d49c5ea61e
     */
    public static function rd_kafka_queue_destroy(?\FFI\CData $rkqu): void
    {
        static::getFFI()->rd_kafka_queue_destroy($rkqu);
    }

    /**
     * <p>Use rd_kafka_queue_destroy() to loose the reference. </p>
     * @param \FFI\CData|null $rk rd_kafka_t* - )
     * @return \FFI\CData|null rd_kafka_queue_t* - a reference to the main librdkafka event queue. This is the queue served by rd_kafka_poll().
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a7f3d675ee029a52bf85fb28f83c38863
     */
    public static function rd_kafka_queue_get_main(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_queue_get_main($rk);
    }

    /**
     * <p>Use rd_kafka_queue_destroy() to loose the reference.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>rd_kafka_queue_destroy() MUST be called on this queue prior to calling rd_kafka_consumer_close(). </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t* - )
     * @return \FFI\CData|null rd_kafka_queue_t* - a reference to the librdkafka consumer queue. This is the queue served by rd_kafka_consumer_poll().
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#acacdb55ae7cb6abfbde89621e512b078
     */
    public static function rd_kafka_queue_get_consumer(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_queue_get_consumer($rk);
    }

    /**
     * <p>Use rd_kafka_queue_destroy() to loose the reference.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>rd_kafka_queue_destroy() MUST be called on this queue</dd>
     * <dd>
     * This function only works on consumers. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $topic const char*
     * @param int|null $partition int32_t
     * @return \FFI\CData|null rd_kafka_queue_t* - a reference to the partition's queue, or NULL if partition is invalid.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ad5319a26efb9f843c6029f7dd54b742d
     */
    public static function rd_kafka_queue_get_partition(?\FFI\CData $rk, ?string $topic, ?int $partition): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_queue_get_partition($rk, $topic, $partition);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return \FFI\CData|null rd_kafka_queue_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_queue_get_background(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_queue_get_background($rk);
    }

    /**
     * <p>Forward/re-route queue <code>src</code> to <code>dst</code>. If <code>dst</code> is <code>NULL</code> the forwarding is removed. </p>
     * <p>The internal refcounts for both queues are increased.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Regardless of whether <code>dst</code> is NULL or not, after calling this function, <code>src</code> will not forward it's fetch queue to the consumer queue. </dd></dl>
     * @param \FFI\CData|null $src rd_kafka_queue_t*
     * @param \FFI\CData|null $dst rd_kafka_queue_t*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a5e2e5571d14636d289f963a270b8e338
     */
    public static function rd_kafka_queue_forward(?\FFI\CData $src, ?\FFI\CData $dst): void
    {
        static::getFFI()->rd_kafka_queue_forward($src, $dst);
    }

    /**
     * <p>Forward librdkafka logs (and debug) to the specified queue for serving with one of the ..poll() calls. </p>
     * <p>This allows an application to serve log callbacks (<code>log_cb</code>) in its thread of choice.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>The configuration property <code>log.queue</code> MUST also be set to true.</dd>
     * <dd>
     * librdkafka maintains its own reference to the provided queue.</dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t* - Queue to forward logs to. If the value is NULL the logs are forwarded to the main queue.
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR on success or an error code on error.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a5c8a3be2f797560b2a39bf56dbd7622d
     */
    public static function rd_kafka_set_log_queue(?\FFI\CData $rk, ?\FFI\CData $rkqu): int
    {
        return static::getFFI()->rd_kafka_set_log_queue($rk, $rkqu);
    }

    /**
     *
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t* - )
     * @return int|null size_t - the current number of elements in queue.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a8f24368f4ff0e042907773f532f62e57
     */
    public static function rd_kafka_queue_length(?\FFI\CData $rkqu): ?int
    {
        return static::getFFI()->rd_kafka_queue_length($rkqu);
    }

    /**
     * <p>Enable IO event triggering for queue. </p>
     * <p>To ease integration with IO based polling loops this API allows an application to create a separate file-descriptor that librdkafka will write <code>payload</code> (of size <code>size</code>) to whenever a new element is enqueued on a previously empty queue.</p>
     * <p>To remove event triggering call with <code>fd</code> = -1.</p>
     * <p>librdkafka will maintain a copy of the <code>payload</code>.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>When using forwarded queues the IO event must only be enabled on the final forwarded-to (destination) queue. </dd></dl>
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @param int|null $fd int
     * @param \FFI\CData|object|string|null $payload void*
     * @param int|null $size size_t
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#acbdd13ab480f6320b2842981eebce784
     */
    public static function rd_kafka_queue_io_event_enable(?\FFI\CData $rkqu, ?int $fd, $payload, ?int $size): void
    {
        static::getFFI()->rd_kafka_queue_io_event_enable($rkqu, $fd, $payload, $size);
    }

    /**
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @param \FFI\CData|\Closure $event_cb void(*)(rd_kafka_t*, void*)
     * @param \FFI\CData|object|string|null $opaque void*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_queue_cb_event_enable(?\FFI\CData $rkqu, $event_cb, $opaque): void
    {
        static::getFFI()->rd_kafka_queue_cb_event_enable($rkqu, $event_cb, $opaque);
    }

    /**
     * <p>Start consuming messages for topic <code>rkt</code> and <code>partition</code> at offset <code>offset</code> which may either be an absolute <code></code>(0..N) or one of the logical offsets: </p>
     * <ul><li>RD_KAFKA_OFFSET_BEGINNING</li>
     * <li>RD_KAFKA_OFFSET_END</li>
     * <li>RD_KAFKA_OFFSET_STORED</li>
     * <li>RD_KAFKA_OFFSET_TAIL</li>
     * </ul><p>rdkafka will attempt to keep <code>queued.min.messages</code> (config property) messages in the local queue by repeatedly fetching batches of messages from the broker until the threshold is reached.</p>
     * <p>The application shall use one of the <code>rd_kafka_consume*()</code> functions to consume messages from the local queue, each kafka message being represented as a <code>rd_kafka_message_t *</code> object.</p>
     * <p><code>rd_kafka_consume_start()</code> must not be called multiple times for the same topic and partition without stopping consumption first with <code>rd_kafka_consume_stop()</code>.</p>
     * <p>Use <code>rd_kafka_errno2err()</code> to convert sytem <code>errno</code> to <code>rd_kafka_resp_err_t</code> </p>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @param int|null $offset int64_t
     * @return int|null int - 0 on success or -1 on error in which case errno is set accordingly:<ul><li>EBUSY - Conflicts with an existing or previous subscription (RD_KAFKA_RESP_ERR__CONFLICT)</li>
     * <li>EINVAL - Invalid offset, or incomplete configuration (lacking group.id) (RD_KAFKA_RESP_ERR__INVALID_ARG)</li>
     * <li>ESRCH - requested <code>partition</code> is invalid. (RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION)</li>
     * <li>ENOENT - topic is unknown in the Kafka cluster. (RD_KAFKA_RESP_ERR__UNKNOWN_TOPIC)</li>
     * </ul>
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ae21dcd2d8c6195baf7f9f4952d7e12d4
     */
    public static function rd_kafka_consume_start(?\FFI\CData $rkt, ?int $partition, ?int $offset): ?int
    {
        return static::getFFI()->rd_kafka_consume_start($rkt, $partition, $offset);
    }

    /**
     * <p>Same as rd_kafka_consume_start() but re-routes incoming messages to the provided queue <code>rkqu</code> (which must have been previously allocated with <code>rd_kafka_queue_new()</code>. </p>
     * <p>The application must use one of the <code>rd_kafka_consume_*_queue()</code> functions to receive fetched messages.</p>
     * <p><code>rd_kafka_consume_start_queue()</code> must not be called multiple times for the same topic and partition without stopping consumption first with <code>rd_kafka_consume_stop()</code>. <code>rd_kafka_consume_start()</code> and <code>rd_kafka_consume_start_queue()</code> must not be combined for the same topic and partition. </p>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @param int|null $offset int64_t
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @return int|null int
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a8e952d7961169471f69c7ddc87041258
     */
    public static function rd_kafka_consume_start_queue(?\FFI\CData $rkt, ?int $partition, ?int $offset, ?\FFI\CData $rkqu): ?int
    {
        return static::getFFI()->rd_kafka_consume_start_queue($rkt, $partition, $offset, $rkqu);
    }

    /**
     * <p>Stop consuming messages for topic <code>rkt</code> and <code>partition</code>, purging all messages currently in the local queue. </p>
     * <p>NOTE: To enforce synchronisation this call will block until the internal fetcher has terminated and offsets are committed to configured storage method.</p>
     * <p>The application needs to be stop all consumers before calling <code>rd_kafka_destroy()</code> on the main object handle.</p>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @return int|null int - 0 on success or -1 on error (see <code>errno</code>).
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#acf07475e5e85e63fc5321a1087288cd4
     */
    public static function rd_kafka_consume_stop(?\FFI\CData $rkt, ?int $partition): ?int
    {
        return static::getFFI()->rd_kafka_consume_stop($rkt, $partition);
    }

    /**
     * <p>Seek consumer for topic+partition to <code>offset</code> which is either an absolute or logical offset. </p>
     * <p>If <code>timeout_ms</code> is not 0 the call will wait this long for the seek to be performed. If the timeout is reached the internal state will be unknown and this function returns <code>RD_KAFKA_RESP_ERR__TIMED_OUT</code>. If <code>timeout_ms</code> is 0 it will initiate the seek but return immediately without any error reporting (e.g., async).</p>
     * <p>This call triggers a fetch queue barrier flush.</p>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @param int|null $offset int64_t
     * @param int|null $timeout_ms int
     * @return int rd_kafka_resp_err_t - <code>RD_KAFKA_RESP_ERR__NO_ERROR</code> on success else an error code.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a6667b162931982e9827e3d86ad22ec7d
     */
    public static function rd_kafka_seek(?\FFI\CData $rkt, ?int $partition, ?int $offset, ?int $timeout_ms): int
    {
        return static::getFFI()->rd_kafka_seek($rkt, $partition, $offset, $timeout_ms);
    }

    /**
     * <p>Consume a single message from topic <code>rkt</code> and <code>partition</code>. </p>
     * <p><code>timeout_ms</code> is maximum amount of time to wait for a message to be received. Consumer must have been previously started with <code>rd_kafka_consume_start()</code>.</p>
     * <p>Returns a message object on success or <code>NULL</code> on error. The message object must be destroyed with <code>rd_kafka_message_destroy()</code> when the application is done with it.</p>
     * <p>Errors (when returning NULL):</p><ul><li>ETIMEDOUT - <code>timeout_ms</code> was reached with no new messages fetched.</li>
     * <li>ENOENT - <code>rkt</code> + <code>partition</code> is unknown. (no prior <code>rd_kafka_consume_start()</code> call)</li>
     * </ul><p>NOTE: The returned message's <code></code>..-&gt;err must be checked for errors. NOTE: <code></code>..-&gt;err <code>==</code> <code>RD_KAFKA_RESP_ERR__PARTITION_EOF</code> signals that the end of the partition has been reached, which should typically not be considered an error. The application should handle this case (e.g., ignore). </p>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @param int|null $timeout_ms int
     * @return \FFI\CData|null rd_kafka_message_t*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#aa49d14e8b742365f9f25d35318ff0b7e
     */
    public static function rd_kafka_consume(?\FFI\CData $rkt, ?int $partition, ?int $timeout_ms): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_consume($rkt, $partition, $timeout_ms);
    }

    /**
     * <p>Consume up to <code>rkmessages_size</code> from topic <code>rkt</code> and <code>partition</code> putting a pointer to each message in the application provided array <code>rkmessages</code> (of size <code>rkmessages_size</code> entries). </p>
     * <p><code>rd_kafka_consume_batch()</code> provides higher throughput performance than <code>rd_kafka_consume()</code>.</p>
     * <p><code>timeout_ms</code> is the maximum amount of time to wait for all of <code>rkmessages_size</code> messages to be put into <code>rkmessages</code>. If no messages were available within the timeout period this function returns 0 and <code>rkmessages</code> remains untouched. This differs somewhat from <code>rd_kafka_consume()</code>.</p>
     * <p>The message objects must be destroyed with <code>rd_kafka_message_destroy()</code> when the application is done with it.</p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_consume() </dd></dl>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @param int|null $timeout_ms int
     * @param \FFI\CData|null $rkmessages rd_kafka_message_t**
     * @param int|null $rkmessages_size size_t
     * @return int|null ssize_t - the number of rkmessages added in <code>rkmessages</code>, or -1 on error (same error codes as for <code>rd_kafka_consume()</code>.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a53511739a2cf498b8d88287fef6873ce
     */
    public static function rd_kafka_consume_batch(?\FFI\CData $rkt, ?int $partition, ?int $timeout_ms, ?\FFI\CData $rkmessages, ?int $rkmessages_size): ?int
    {
        return static::getFFI()->rd_kafka_consume_batch($rkt, $partition, $timeout_ms, $rkmessages, $rkmessages_size);
    }

    /**
     * <p>Consumes messages from topic <code>rkt</code> and <code>partition</code>, calling the provided callback for each consumed messsage. </p>
     * <p><code>rd_kafka_consume_callback()</code> provides higher throughput performance than both <code>rd_kafka_consume()</code> and <code>rd_kafka_consume_batch()</code>.</p>
     * <p><code>timeout_ms</code> is the maximum amount of time to wait for one or more messages to arrive.</p>
     * <p>The provided <code>consume_cb</code> function is called for each message, the application <b>MUST</b> <b>NOT</b> call <code>rd_kafka_message_destroy()</code> on the provided <code>rkmessage</code>.</p>
     * <p>The <code>opaque</code> argument is passed to the 'consume_cb' as <code>opaque</code>.</p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_consume() </dd></dl>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @param int|null $timeout_ms int
     * @param \FFI\CData|\Closure $consume_cb void(*)(rd_kafka_message_t*, void*)
     * @param \FFI\CData|object|string|null $opaque void*
     * @return int|null int - the number of messages processed or -1 on error.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a303fa0f0da7f3c28bed35570adc983c6
     */
    public static function rd_kafka_consume_callback(?\FFI\CData $rkt, ?int $partition, ?int $timeout_ms, $consume_cb, $opaque): ?int
    {
        return static::getFFI()->rd_kafka_consume_callback($rkt, $partition, $timeout_ms, $consume_cb, $opaque);
    }

    /**
     * <p>Consume from queue. </p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_consume() </dd></dl>
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @param int|null $timeout_ms int
     * @return \FFI\CData|null rd_kafka_message_t*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a8ff0b80fccb3a5bd31b1baaf20e4ca16
     */
    public static function rd_kafka_consume_queue(?\FFI\CData $rkqu, ?int $timeout_ms): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_consume_queue($rkqu, $timeout_ms);
    }

    /**
     * <p>Consume batch of messages from queue. </p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_consume_batch() </dd></dl>
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @param int|null $timeout_ms int
     * @param \FFI\CData|null $rkmessages rd_kafka_message_t**
     * @param int|null $rkmessages_size size_t
     * @return int|null ssize_t
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a3d949238471993b18537855aad28fa23
     */
    public static function rd_kafka_consume_batch_queue(?\FFI\CData $rkqu, ?int $timeout_ms, ?\FFI\CData $rkmessages, ?int $rkmessages_size): ?int
    {
        return static::getFFI()->rd_kafka_consume_batch_queue($rkqu, $timeout_ms, $rkmessages, $rkmessages_size);
    }

    /**
     * <p>Consume multiple messages from queue with callback. </p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_consume_callback() </dd></dl>
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @param int|null $timeout_ms int
     * @param \FFI\CData|\Closure $consume_cb void(*)(rd_kafka_message_t*, void*)
     * @param \FFI\CData|object|string|null $opaque void*
     * @return int|null int
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#abb1aaca2499c2e7d6da37dc28953d532
     */
    public static function rd_kafka_consume_callback_queue(?\FFI\CData $rkqu, ?int $timeout_ms, $consume_cb, $opaque): ?int
    {
        return static::getFFI()->rd_kafka_consume_callback_queue($rkqu, $timeout_ms, $consume_cb, $opaque);
    }

    /**
     * <p>Store offset <code>offset</code> for topic <code>rkt</code> partition <code>partition</code>. </p>
     * <p>The offset will be committed (written) to the offset store according to <code><code>auto.commit.interval.ms</code></code>.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd><code><code>auto.commit.enable</code></code> must be set to "false" when using this API.</dd></dl>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @param int|null $offset int64_t
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR on success or an error code on error.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a784186db1d2cb6ceebcd5606d38db4c4
     */
    public static function rd_kafka_offset_store(?\FFI\CData $rkt, ?int $partition, ?int $offset): int
    {
        return static::getFFI()->rd_kafka_offset_store($rkt, $partition, $offset);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $offsets rd_kafka_topic_partition_list_t*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_offsets_store(?\FFI\CData $rk, ?\FFI\CData $offsets): int
    {
        return static::getFFI()->rd_kafka_offsets_store($rk, $offsets);
    }

    /**
     * <p>Subscribe to topic set using balanced consumer groups. </p>
     * <p>Wildcard (regex) topics are supported by the librdkafka assignor: any topic name in the <code>topics</code> list that is prefixed with <code>"^"</code> will be regex-matched to the full list of topics in the cluster and matching topics will be added to the subscription list.</p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $topics rd_kafka_topic_partition_list_t*
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR on success or RD_KAFKA_RESP_ERR__INVALID_ARG if list is empty, contains invalid topics or regexes.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a0ebe15e9d0f39ccc84e9686f0fcf46f1
     */
    public static function rd_kafka_subscribe(?\FFI\CData $rk, ?\FFI\CData $topics): int
    {
        return static::getFFI()->rd_kafka_subscribe($rk, $topics);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_unsubscribe(?\FFI\CData $rk): int
    {
        return static::getFFI()->rd_kafka_unsubscribe($rk);
    }

    /**
     * <p>Returns the current topic subscription. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>The application is responsible for calling rd_kafka_topic_partition_list_destroy on the returned list. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $topics rd_kafka_topic_partition_list_t**
     * @return int rd_kafka_resp_err_t - An error code on failure, otherwise <code>topic</code> is updated to point to a newly allocated topic list (possibly empty).
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ab66a2c014db2e652aa12466b137a6200
     */
    public static function rd_kafka_subscription(?\FFI\CData $rk, ?\FFI\CData $topics): int
    {
        return static::getFFI()->rd_kafka_subscription($rk, $topics);
    }

    /**
     * <p>Poll the consumer for messages or events. </p>
     * <p>Will block for at most <code>timeout_ms</code> milliseconds.</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>An application should make sure to call consumer_poll() at regular intervals, even if no messages are expected, to serve any queued callbacks waiting to be called. This is especially important when a rebalance_cb has been registered as it needs to be called and handled properly to synchronize internal consumer state.</dd></dl><dl class="section see"><dt>See also</dt><dd>rd_kafka_message_t </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $timeout_ms int
     * @return \FFI\CData|null rd_kafka_message_t* - A message object which is a proper message if <code>-&gt;err</code> is RD_KAFKA_RESP_ERR_NO_ERROR, or an event or error for any other value.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a65cc6cb9bd72c4084f074af0361ceddf
     */
    public static function rd_kafka_consumer_poll(?\FFI\CData $rk, ?int $timeout_ms): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_consumer_poll($rk, $timeout_ms);
    }

    /**
     * <p>Close down the KafkaConsumer. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>This call will block until the consumer has revoked its assignment, calling the <code>rebalance_cb</code> if it is configured, committed offsets to broker, and left the consumer group. The maximum blocking time is roughly limited to session.timeout.ms.</dd></dl><dl class="section remark"><dt>Remarks</dt><dd>The application still needs to call rd_kafka_destroy() after this call finishes to clean up the underlying handle resources. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t* - )
     * @return int rd_kafka_resp_err_t - An error code indicating if the consumer close was succesful or not.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a37b54d329e12d745889defe96e7d043d
     */
    public static function rd_kafka_consumer_close(?\FFI\CData $rk): int
    {
        return static::getFFI()->rd_kafka_consumer_close($rk);
    }

    /**
     * <p>Atomic assignment of partitions to consume. </p>
     * <p>The new <code>partitions</code> will replace the existing assignment.</p>
     * <p>When used from a rebalance callback the application shall pass the partition list passed to the callback (or a copy of it) (even if the list is empty) rather than NULL to maintain internal join state.</p>
     * <p>A zero-length <code>partitions</code> will treat the partitions as a valid, albeit empty, assignment, and maintain internal state, while a <code>NULL</code> value for <code>partitions</code> will reset and clear the internal state. </p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $partitions rd_kafka_topic_partition_list_t*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a0566419eff2001f8371e3b50aa7d26e9
     */
    public static function rd_kafka_assign(?\FFI\CData $rk, ?\FFI\CData $partitions): int
    {
        return static::getFFI()->rd_kafka_assign($rk, $partitions);
    }

    /**
     * <p>Returns the current partition assignment. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>The application is responsible for calling rd_kafka_topic_partition_list_destroy on the returned list. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $partitions rd_kafka_topic_partition_list_t**
     * @return int rd_kafka_resp_err_t - An error code on failure, otherwise <code>partitions</code> is updated to point to a newly allocated partition list (possibly empty).
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a10a00cc624a46209fe1192cfc56cce59
     */
    public static function rd_kafka_assignment(?\FFI\CData $rk, ?\FFI\CData $partitions): int
    {
        return static::getFFI()->rd_kafka_assignment($rk, $partitions);
    }

    /**
     * <p>Commit offsets on broker for the provided list of partitions. </p>
     * <p><code>offsets</code> should contain <code>topic</code>, <code>partition</code>, <code>offset</code> and possibly <code>metadata</code>. If <code>offsets</code> is NULL the current partition assignment will be used instead.</p>
     * <p>If <code>async</code> is false this operation will block until the broker offset commit is done, returning the resulting success or error code.</p>
     * <p>If a rd_kafka_conf_set_offset_commit_cb() offset commit callback has been configured the callback will be enqueued for a future call to rd_kafka_poll(), rd_kafka_consumer_poll() or similar. </p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $offsets rd_kafka_topic_partition_list_t*
     * @param int|null $async int
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ab96539928328f14c3c9177ea0c896c87
     */
    public static function rd_kafka_commit(?\FFI\CData $rk, ?\FFI\CData $offsets, ?int $async): int
    {
        return static::getFFI()->rd_kafka_commit($rk, $offsets, $async);
    }

    /**
     * <p>Commit message's offset on broker for the message's partition. </p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_commit </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @param int|null $async int
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a99fb25d50216e4e20d303bf8a4a62883
     */
    public static function rd_kafka_commit_message(?\FFI\CData $rk, ?\FFI\CData $rkmessage, ?int $async): int
    {
        return static::getFFI()->rd_kafka_commit_message($rk, $rkmessage, $async);
    }

    /**
     * <p>Commit offsets on broker for the provided list of partitions. </p>
     * <p>See rd_kafka_commit for <code>offsets</code> semantics.</p>
     * <p>The result of the offset commit will be posted on the provided <code>rkqu</code> queue.</p>
     * <p>If the application uses one of the poll APIs (rd_kafka_poll(), rd_kafka_consumer_poll(), rd_kafka_queue_poll(), ..) to serve the queue the <code>cb</code> callback is required. <code>opaque</code> is passed to the callback.</p>
     * <p>If using the event API the callback is ignored and the offset commit result will be returned as an RD_KAFKA_EVENT_COMMIT event. The <code>opaque</code> value will be available with rd_kafka_event_opaque()</p>
     * <p>If <code>rkqu</code> is NULL a temporary queue will be created and the callback will be served by this call.</p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_commit() </dd>
     * <dd>
     * rd_kafka_conf_set_offset_commit_cb() </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $offsets rd_kafka_topic_partition_list_t*
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @param \FFI\CData|\Closure $cb void(*)(rd_kafka_t*, rd_kafka_resp_err_t, rd_kafka_topic_partition_list_t*, void*)
     * @param \FFI\CData|object|string|null $opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#aa793dd9c195f39bcb69465cebf534c47
     */
    public static function rd_kafka_commit_queue(?\FFI\CData $rk, ?\FFI\CData $offsets, ?\FFI\CData $rkqu, $cb, $opaque): int
    {
        return static::getFFI()->rd_kafka_commit_queue($rk, $offsets, $rkqu, $cb, $opaque);
    }

    /**
     * <p>Retrieve committed offsets for topics+partitions. </p>
     * <p>The <code>offset</code> field of each requested partition will either be set to stored offset or to RD_KAFKA_OFFSET_INVALID in case there was no stored offset for that partition.</p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $partitions rd_kafka_topic_partition_list_t*
     * @param int|null $timeout_ms int
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR on success in which case the <code>offset</code> or <code>err</code> field of each <code>partitions'</code> element is filled in with the stored offset, or a partition specific error. Else returns an error code.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a39846ae321a03c4679c9c659f18adf13
     */
    public static function rd_kafka_committed(?\FFI\CData $rk, ?\FFI\CData $partitions, ?int $timeout_ms): int
    {
        return static::getFFI()->rd_kafka_committed($rk, $partitions, $timeout_ms);
    }

    /**
     * <p>Retrieve current positions (offsets) for topics+partitions. </p>
     * <p>The <code>offset</code> field of each requested partition will be set to the offset of the last consumed message + 1, or RD_KAFKA_OFFSET_INVALID in case there was no previous message.</p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $partitions rd_kafka_topic_partition_list_t*
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR_NO_ERROR on success in which case the <code>offset</code> or <code>err</code> field of each <code>partitions'</code> element is filled in with the stored offset, or a partition specific error. Else returns an error code.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a6e9e36bd9e6bf84a9f3092fcbfa3a9ac
     */
    public static function rd_kafka_position(?\FFI\CData $rk, ?\FFI\CData $partitions): int
    {
        return static::getFFI()->rd_kafka_position($rk, $partitions);
    }

    /**
     * <p>Produce and send a single message to broker. </p>
     * <p><code>rkt</code> is the target topic which must have been previously created with <code>rd_kafka_topic_new()</code>.</p>
     * <p><code>rd_kafka_produce()</code> is an asynch non-blocking API.</p>
     * <p><code>partition</code> is the target partition, either:</p><ul><li>RD_KAFKA_PARTITION_UA (unassigned) for automatic partitioning using the topic's partitioner function, or</li>
     * <li>a fixed partition (0..N)</li>
     * </ul><p><code>msgflags</code> is zero or more of the following flags OR:ed together: RD_KAFKA_MSG_F_BLOCK - block <code>produce*</code>() call if <code>queue.buffering.max.messages</code> or <code>queue.buffering.max.kbytes</code> are exceeded. Messages are considered in-queue from the point they are accepted by produce() until their corresponding delivery report callback/event returns. It is thus a requirement to call rd_kafka_poll() (or equiv.) from a separate thread when F_BLOCK is used. See WARNING on <code>RD_KAFKA_MSG_F_BLOCK</code> above.</p>
     * <p>RD_KAFKA_MSG_F_FREE - rdkafka will free(3) <code>payload</code> when it is done with it. RD_KAFKA_MSG_F_COPY - the <code>payload</code> data will be copied and the <code>payload</code> pointer will not be used by rdkafka after the call returns.</p>
     * <p>.._F_FREE and .._F_COPY are mutually exclusive.</p>
     * <p>If the function returns -1 and RD_KAFKA_MSG_F_FREE was specified, then the memory associated with the payload is still the caller's responsibility.</p>
     * <p><code>payload</code> is the message payload of size <code>len</code> bytes.</p>
     * <p><code>key</code> is an optional message key of size <code>keylen</code> bytes, if non-NULL it will be passed to the topic partitioner as well as be sent with the message to the broker and passed on to the consumer.</p>
     * <p><code>msg_opaque</code> is an optional application-provided per-message opaque pointer that will provided in the delivery report callback (<code>dr_cb</code>) for referencing this message.</p>
     * <p>Returns 0 on success or -1 on error in which case errno is set accordingly:</p><ul><li>ENOBUFS - maximum number of outstanding messages has been reached: "queue.buffering.max.messages" (RD_KAFKA_RESP_ERR__QUEUE_FULL)</li>
     * <li>EMSGSIZE - message is larger than configured max size: "messages.max.bytes". (RD_KAFKA_RESP_ERR_MSG_SIZE_TOO_LARGE)</li>
     * <li>ESRCH - requested <code>partition</code> is unknown in the Kafka cluster. (RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION)</li>
     * <li>ENOENT - topic is unknown in the Kafka cluster. (RD_KAFKA_RESP_ERR__UNKNOWN_TOPIC)</li>
     * </ul><dl class="section see"><dt>See also</dt><dd>Use rd_kafka_errno2err() to convert <code>errno</code> to rdkafka error code. </dd></dl>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @param int|null $msgflags int
     * @param \FFI\CData|object|string|null $payload void*
     * @param int|null $len size_t
     * @param \FFI\CData|object|string|null $key void*
     * @param int|null $keylen size_t
     * @param \FFI\CData|object|string|null $msg_opaque void*
     * @return int|null int
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ae24d8ebf1ea15ed8ea0ea40f74662736
     */
    public static function rd_kafka_produce(?\FFI\CData $rkt, ?int $partition, ?int $msgflags, $payload, ?int $len, $key, ?int $keylen, $msg_opaque): ?int
    {
        return static::getFFI()->rd_kafka_produce($rkt, $partition, $msgflags, $payload, $len, $key, $keylen, $msg_opaque);
    }

    /**
     * <p>Produce and send a single message to broker. </p>
     * <p>The message is defined by a va-arg list using <code>rd_kafka_vtype_t</code> tag tuples which must be terminated with a single <code>RD_KAFKA_V_END</code>.</p>
     * <dl class="section see"><dt>See also</dt><dd>rd_kafka_produce, RD_KAFKA_V_END </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param mixed ...$args
     * @return int rd_kafka_resp_err_t - <code>RD_KAFKA_RESP_ERR_NO_ERROR</code> on success, else an error code.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ac3a111ec3e6729609d498fec7b619efc
     */
    public static function rd_kafka_producev(?\FFI\CData $rk, ...$args): int
    {
        return static::getFFI()->rd_kafka_producev($rk, ...$args);
    }

    /**
     * <p>Produce multiple messages. </p>
     * <p>If partition is RD_KAFKA_PARTITION_UA the configured partitioner will be run for each message (slower), otherwise the messages will be enqueued to the specified partition directly (faster).</p>
     * <p>The messages are provided in the array <code>rkmessages</code> of count <code>message_cnt</code> elements. The <code>partition</code> and <code>msgflags</code> are used for all provided messages.</p>
     * <p>Honoured <code>rkmessages</code>[] fields are:</p><ul><li>payload,len Message payload and length</li>
     * <li>key,key_len Optional message key</li>
     * <li>_private Message opaque pointer (msg_opaque)</li>
     * <li>err Will be set according to success or failure. Application only needs to check for errors if return value != <code>message_cnt</code>.</li>
     * </ul>
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param int|null $partition int32_t
     * @param int|null $msgflags int
     * @param \FFI\CData|null $rkmessages rd_kafka_message_t*
     * @param int|null $message_cnt int
     * @return int|null int - the number of messages succesfully enqueued for producing.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a7ad15c71f228c47946500a0e5c6f88ed
     */
    public static function rd_kafka_produce_batch(?\FFI\CData $rkt, ?int $partition, ?int $msgflags, ?\FFI\CData $rkmessages, ?int $message_cnt): ?int
    {
        return static::getFFI()->rd_kafka_produce_batch($rkt, $partition, $msgflags, $rkmessages, $message_cnt);
    }

    /**
     * <p>Wait until all outstanding produce requests, et.al, are completed. This should typically be done prior to destroying a producer instance to make sure all queued and in-flight produce requests are completed before terminating. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>This function will call rd_kafka_poll() and thus trigger callbacks.</dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $timeout_ms int
     * @return int rd_kafka_resp_err_t - RD_KAFKA_RESP_ERR__TIMED_OUT if <code>timeout_ms</code> was reached before all outstanding requests were completed, else RD_KAFKA_RESP_ERR_NO_ERROR
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#aaff06c4372bce917c17f3c1a5d8b205d
     */
    public static function rd_kafka_flush(?\FFI\CData $rk, ?int $timeout_ms): int
    {
        return static::getFFI()->rd_kafka_flush($rk, $timeout_ms);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $purge_flags int
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_purge(?\FFI\CData $rk, ?int $purge_flags): int
    {
        return static::getFFI()->rd_kafka_purge($rk, $purge_flags);
    }

    /**
     * <p>Request Metadata from broker. </p>
     * <p>Parameters:</p><ul><li><code>all_topics</code> if non-zero: request info about all topics in cluster, if zero: only request info about locally known topics.</li>
     * <li><code>only_rkt</code> only request info about this topic</li>
     * <li><code>metadatap</code> pointer to hold metadata result. The <code>*metadatap</code> pointer must be released with rd_kafka_metadata_destroy().</li>
     * <li><code>timeout_ms</code> maximum response time before failing.</li>
     * </ul><p>Returns RD_KAFKA_RESP_ERR_NO_ERROR on success (in which case *metadatap) will be set, else RD_KAFKA_RESP_ERR__TIMED_OUT on timeout or other error code on error. </p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $all_topics int
     * @param \FFI\CData|null $only_rkt rd_kafka_topic_t*
     * @param \FFI\CData|null $metadatap struct rd_kafka_metadata**
     * @param int|null $timeout_ms int
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a84bba4a4b13fdb515f1a22d6fd4f7344
     */
    public static function rd_kafka_metadata(?\FFI\CData $rk, ?int $all_topics, ?\FFI\CData $only_rkt, ?\FFI\CData $metadatap, ?int $timeout_ms): int
    {
        return static::getFFI()->rd_kafka_metadata($rk, $all_topics, $only_rkt, $metadatap, $timeout_ms);
    }

    /**
     * @param \FFI\CData|\Closure $metadata rd_kafka_resp_err_t(rd_kafka_metadata*)(rd_kafka_t*, int, rd_kafka_topic_t*, struct rd_kafka_metadata**, int)
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_metadata_destroy($metadata): void
    {
        static::getFFI()->rd_kafka_metadata_destroy($metadata);
    }

    /**
     * <p>List and describe client groups in cluster. </p>
     * <p><code>group</code> is an optional group name to describe, otherwise (<code>NULL</code>) all groups are returned.</p>
     * <p><code>timeout_ms</code> is the (approximate) maximum time to wait for response from brokers and must be a positive value.</p>
     * <dl class="section see"><dt>See also</dt><dd>Use rd_kafka_group_list_destroy() to release list memory. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $group const char*
     * @param \FFI\CData|null $grplistp struct rd_kafka_group_list**
     * @param int|null $timeout_ms int
     * @return int rd_kafka_resp_err_t - <code>RD_KAFKA_RESP_ERR__NO_ERROR</code> on success and <code>grplistp</code> is updated to point to a newly allocated list of groups. Else returns an error code on failure and <code>grplistp</code> remains untouched.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a6cfc79819453ecd4aa94fbae6dbbea0a
     */
    public static function rd_kafka_list_groups(?\FFI\CData $rk, ?string $group, ?\FFI\CData $grplistp, ?int $timeout_ms): int
    {
        return static::getFFI()->rd_kafka_list_groups($rk, $group, $grplistp, $timeout_ms);
    }

    /**
     * @param \FFI\CData|null $grplist struct rd_kafka_group_list*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_group_list_destroy(?\FFI\CData $grplist): void
    {
        static::getFFI()->rd_kafka_group_list_destroy($grplist);
    }

    /**
     * <p>Adds one or more brokers to the kafka handle's list of initial bootstrap brokers. </p>
     * <p>Additional brokers will be discovered automatically as soon as rdkafka connects to a broker by querying the broker metadata.</p>
     * <p>If a broker name resolves to multiple addresses (and possibly address families) all will be used for connection attempts in round-robin fashion.</p>
     * <p><code>brokerlist</code> is a ,-separated list of brokers in the format: <code>&lt;broker1&gt;</code>,&lt;broker2&gt;,.. Where each broker is in either the host or URL based format: <code>&lt;host&gt;</code>[:&lt;port&gt;] <code>&lt;proto&gt;</code>://&lt;host&gt;[:port] <code>&lt;proto&gt;</code> is either <code>PLAINTEXT</code>, <code>SSL</code>, <code>SASL</code>, <code>SASL_PLAINTEXT</code> The two formats can be mixed but ultimately the value of the <code>security.protocol</code> config property decides what brokers are allowed.</p>
     * <p>Example: brokerlist = "broker1:10000,broker2" brokerlist = "SSL://broker3:9000,ssl://broker2"</p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Brokers may also be defined with the <code>metadata.broker.list</code> or <code>bootstrap.servers</code> configuration property (preferred method). </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $brokerlist const char*
     * @return int|null int - the number of brokers successfully added.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ab83da8da989fe41693d78d982c7ae6b7
     */
    public static function rd_kafka_brokers_add(?\FFI\CData $rk, ?string $brokerlist): ?int
    {
        return static::getFFI()->rd_kafka_brokers_add($rk, $brokerlist);
    }

    /**
     * <p>Set logger function. </p>
     * <p>The default is to print to stderr, but a syslog logger is also available, see rd_kafka_log_(print|syslog) for the builtin alternatives. Alternatively the application may provide its own logger callback. Or pass 'func' as NULL to disable logging.</p>
     * <dl class="deprecated"><dt><b>Deprecated:</b></dt><dd>Use rd_kafka_conf_set_log_cb()</dd></dl><dl class="section remark"><dt>Remarks</dt><dd><code>rk</code> may be passed as NULL in the callback. </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|\Closure $func void(*)(rd_kafka_t*, int, const char*, const char*)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a9e4af9adee414af74c7817403f7c4a53
     */
    public static function rd_kafka_set_logger(?\FFI\CData $rk, $func): void
    {
        static::getFFI()->rd_kafka_set_logger($rk, $func);
    }

    /**
     * <p>Specifies the maximum logging level produced by internal kafka logging and debugging. </p>
     * <p>If the <code>"debug"</code> configuration property is set the level is automatically adjusted to <code>LOG_DEBUG</code> (7). </p>
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $level int
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#acadeefced6bb60acd27e7a0dad553aa4
     */
    public static function rd_kafka_set_log_level(?\FFI\CData $rk, ?int $level): void
    {
        static::getFFI()->rd_kafka_set_log_level($rk, $level);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $level int
     * @param string|null $fac const char*
     * @param string|null $buf const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_log_print(?\FFI\CData $rk, ?int $level, ?string $fac, ?string $buf): void
    {
        static::getFFI()->rd_kafka_log_print($rk, $level, $fac, $buf);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $level int
     * @param string|null $fac const char*
     * @param string|null $buf const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_log_syslog(?\FFI\CData $rk, ?int $level, ?string $fac, ?string $buf): void
    {
        static::getFFI()->rd_kafka_log_syslog($rk, $level, $fac, $buf);
    }

    /**
     * <p>Returns the current out queue length. </p>
     * <p>The out queue contains messages waiting to be sent to, or acknowledged by, the broker.</p>
     * <p>An application should wait for this queue to reach zero before terminating to make sure outstanding requests (such as offset commits) are fully processed.</p>
     * @param \FFI\CData|null $rk rd_kafka_t* - )
     * @return int|null int - number of messages in the out queue.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ad4b3b7659cf9a79d3353810d6b625bb7
     */
    public static function rd_kafka_outq_len(?\FFI\CData $rk): ?int
    {
        return static::getFFI()->rd_kafka_outq_len($rk);
    }

    /**
     * <p>Dumps rdkafka's internal state for handle <code>rk</code> to stream <code>fp</code>. </p>
     * <p>This is only useful for debugging rdkafka, showing state and statistics for brokers, topics, partitions, etc. </p>
     * @param \FFI\CData|null $fp FILE*
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a27a46f74ec4ccc9c0b36dbcf546908a1
     */
    public static function rd_kafka_dump(?\FFI\CData $fp, ?\FFI\CData $rk): void
    {
        static::getFFI()->rd_kafka_dump($fp, $rk);
    }

    /**
     * <p>Retrieve the current number of threads in use by librdkafka. </p>
     * <p>Used by regression tests. </p>
     * @return int|null int - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a0901699375c972b807ba5255773f017f
     */
    public static function rd_kafka_thread_cnt(): ?int
    {
        return static::getFFI()->rd_kafka_thread_cnt();
    }

    /**
     * <p>Wait for all rd_kafka_t objects to be destroyed. </p>
     * <p>Returns 0 if all kafka objects are now destroyed, or -1 if the timeout was reached. Since <code>rd_kafka_destroy()</code> is an asynch operation the <code>rd_kafka_wait_destroyed()</code> function can be used for applications where a clean shutdown is required. </p>
     * @param int|null $timeout_ms int - )
     * @return int|null int
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#aa90f2c92a382dbd0a090d40caa73356d
     */
    public static function rd_kafka_wait_destroyed(?int $timeout_ms): ?int
    {
        return static::getFFI()->rd_kafka_wait_destroyed($timeout_ms);
    }

    /**
     * @return int|null int
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_unittest(): ?int
    {
        return static::getFFI()->rd_kafka_unittest();
    }

    /**
     * <p>Redirect the main (rd_kafka_poll()) queue to the KafkaConsumer's queue (rd_kafka_consumer_poll()). </p>
     * <dl class="section warning"><dt>Warning</dt><dd>It is not permitted to call rd_kafka_poll() after directing the main queue with rd_kafka_poll_set_consumer(). </dd></dl>
     * @param \FFI\CData|null $rk rd_kafka_t* - )
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a9bfa0a1dd3f866cbf0c82fc089bd7904
     */
    public static function rd_kafka_poll_set_consumer(?\FFI\CData $rk): int
    {
        return static::getFFI()->rd_kafka_poll_set_consumer($rk);
    }

    /**
     * <dl class="section remark"><dt>Remarks</dt><dd>As a convenience it is okay to pass <code>rkev</code> as NULL in which case RD_KAFKA_EVENT_NONE is returned. </dd></dl>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @return int|null rd_kafka_event_type_t - the event type for the given event.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a108de3729a4aa609a72a458a9de02d1d
     */
    public static function rd_kafka_event_type(?\FFI\CData $rkev): ?int
    {
        return static::getFFI()->rd_kafka_event_type($rkev);
    }

    /**
     * <dl class="section remark"><dt>Remarks</dt><dd>As a convenience it is okay to pass <code>rkev</code> as NULL in which case the name for RD_KAFKA_EVENT_NONE is returned. </dd></dl>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @return string|null const char* - the event type's name for the given event.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a608193d1fb486f78c79497c8c5b63866
     */
    public static function rd_kafka_event_name(?\FFI\CData $rkev): ?string
    {
        return static::getFFI()->rd_kafka_event_name($rkev);
    }

    /**
     * <p>Destroy an event. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Any references to this event, such as extracted messages, will not be usable after this call.</dd>
     * <dd>
     * As a convenience it is okay to pass <code>rkev</code> as NULL in which case no action is performed. </dd></dl>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#af1835c85aa202caf629861f29f475099
     */
    public static function rd_kafka_event_destroy(?\FFI\CData $rkev): void
    {
        static::getFFI()->rd_kafka_event_destroy($rkev);
    }

    /**
     * <p>Call repeatedly until it returns NULL.</p>
     * <p>Event types:</p><ul><li>RD_KAFKA_EVENT_FETCH (1 message)</li>
     * <li>RD_KAFKA_EVENT_DR (&gt;=1 message(s))</li>
     * </ul><dl class="section remark"><dt>Remarks</dt><dd>The returned message(s) MUST NOT be freed with rd_kafka_message_destroy(). </dd></dl>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @return \FFI\CData|null const rd_kafka_message_t* - the next message from an event.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a3a855eb7bdf17f5797d4911362a5fc7c
     */
    public static function rd_kafka_event_message_next(?\FFI\CData $rkev): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_event_message_next($rkev);
    }

    /**
     * <p>Extacts <code>size</code> message(s) from the event into the pre-allocated array <code>rkmessages</code>. </p>
     * <p>Event types:</p><ul><li>RD_KAFKA_EVENT_FETCH (1 message)</li>
     * <li>RD_KAFKA_EVENT_DR (&gt;=1 message(s))</li>
     * </ul>
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @param \FFI\CData|null $rkmessages const rd_kafka_message_t**
     * @param int|null $size size_t
     * @return int|null size_t - the number of messages extracted.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a18a17000ebe58eabcdafab37924442b8
     */
    public static function rd_kafka_event_message_array(?\FFI\CData $rkev, ?\FFI\CData $rkmessages, ?int $size): ?int
    {
        return static::getFFI()->rd_kafka_event_message_array($rkev, $rkmessages, $size);
    }

    /**
     * <p>Event types:</p><ul><li>RD_KAFKA_EVENT_FETCH (1 message)</li>
     * <li>RD_KAFKA_EVENT_DR (&gt;=1 message(s)) </li>
     * </ul>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @return int|null size_t - the number of remaining messages in the event.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a61d9d106c8956f379bb77d393b8acf90
     */
    public static function rd_kafka_event_message_count(?\FFI\CData $rkev): ?int
    {
        return static::getFFI()->rd_kafka_event_message_count($rkev);
    }

    /**
     * <p>Event types:</p><ul><li>all </li>
     * </ul>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @return int rd_kafka_resp_err_t - the error code for the event.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#aa28b7d6bb4885843f9a8b9bafa0e15a5
     */
    public static function rd_kafka_event_error(?\FFI\CData $rkev): int
    {
        return static::getFFI()->rd_kafka_event_error($rkev);
    }

    /**
     * <p>Event types:</p><ul><li>all </li>
     * </ul>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @return string|null const char* - the error string (if any). An application should check that rd_kafka_event_error() returns non-zero before calling this function.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#ad76a1b2d6c4f1727725b075678b88793
     */
    public static function rd_kafka_event_error_string(?\FFI\CData $rkev): ?string
    {
        return static::getFFI()->rd_kafka_event_error_string($rkev);
    }

    /**
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @return int|null int
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_event_error_is_fatal(?\FFI\CData $rkev): ?int
    {
        return static::getFFI()->rd_kafka_event_error_is_fatal($rkev);
    }

    /**
     * <p>Event types:</p><ul><li>RD_KAFKA_OFFSET_COMMIT </li>
     * </ul>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @return \FFI\CData|object|string|null void* - the user opaque (if any)
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a8650ed2a19108d490a65c9aff3e66525
     */
    public static function rd_kafka_event_opaque(?\FFI\CData $rkev)
    {
        return static::getFFI()->rd_kafka_event_opaque($rkev);
    }

    /**
     * <p>Extract log message from the event. </p>
     * <p>Event types:</p><ul><li>RD_KAFKA_EVENT_LOG</li>
     * </ul>
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @param \FFI\CData|null $fac char**
     * @param \FFI\CData|null $str char**
     * @param \FFI\CData|null $level int*
     * @return int|null int - 0 on success or -1 if unsupported event type.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a535efaa16772642d724bedca414c17c7
     */
    public static function rd_kafka_event_log(?\FFI\CData $rkev, ?\FFI\CData $fac, ?\FFI\CData $str, ?\FFI\CData $level): ?int
    {
        return static::getFFI()->rd_kafka_event_log($rkev, $fac, $str, $level);
    }

    /**
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_event_stats(?\FFI\CData $rkev): ?string
    {
        return static::getFFI()->rd_kafka_event_stats($rkev);
    }

    /**
     * <dl class="section remark"><dt>Remarks</dt><dd>The list MUST NOT be freed with rd_kafka_topic_partition_list_destroy()</dd></dl><p>Event types:</p><ul><li>RD_KAFKA_EVENT_REBALANCE</li>
     * <li>RD_KAFKA_EVENT_OFFSET_COMMIT </li>
     * </ul>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @return \FFI\CData|null rd_kafka_topic_partition_list_t* - the topic partition list from the event.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#abc8f98c9b35be497251fb8515e9e6633
     */
    public static function rd_kafka_event_topic_partition_list(?\FFI\CData $rkev): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_event_topic_partition_list($rkev);
    }

    /**
     * <dl class="section remark"><dt>Remarks</dt><dd>The returned pointer MUST be freed with rd_kafka_topic_partition_destroy().</dd></dl><p>Event types: RD_KAFKA_EVENT_ERROR (for partition level errors) </p>
     * @param \FFI\CData|null $rkev rd_kafka_event_t* - )
     * @return \FFI\CData|null rd_kafka_topic_partition_t* - a newly allocated topic_partition container, if applicable for the event type, else NULL.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#abf4cce46d6e566dd35865c0451b76afe
     */
    public static function rd_kafka_event_topic_partition(?\FFI\CData $rkev): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_event_topic_partition($rkev);
    }

    /**
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @return \FFI\CData|null const rd_kafka_CreateTopics_result_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_event_CreateTopics_result(?\FFI\CData $rkev): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_event_CreateTopics_result($rkev);
    }

    /**
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @return \FFI\CData|null const rd_kafka_DeleteTopics_result_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_event_DeleteTopics_result(?\FFI\CData $rkev): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_event_DeleteTopics_result($rkev);
    }

    /**
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @return \FFI\CData|null const rd_kafka_CreatePartitions_result_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_event_CreatePartitions_result(?\FFI\CData $rkev): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_event_CreatePartitions_result($rkev);
    }

    /**
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @return \FFI\CData|null const rd_kafka_AlterConfigs_result_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_event_AlterConfigs_result(?\FFI\CData $rkev): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_event_AlterConfigs_result($rkev);
    }

    /**
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @return \FFI\CData|null const rd_kafka_DescribeConfigs_result_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_event_DescribeConfigs_result(?\FFI\CData $rkev): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_event_DescribeConfigs_result($rkev);
    }

    /**
     * <p>Poll a queue for an event for max <code>timeout_ms</code>. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>Use rd_kafka_event_destroy() to free the event. </dd></dl>
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @param int|null $timeout_ms int
     * @return \FFI\CData|null rd_kafka_event_t* - an event, or NULL.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a2f147ed1c554c9048893fb1adde86dfa
     */
    public static function rd_kafka_queue_poll(?\FFI\CData $rkqu, ?int $timeout_ms): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_queue_poll($rkqu, $timeout_ms);
    }

    /**
     * <p>Poll a queue for events served through callbacks for max <code>timeout_ms</code>. </p>
     * <dl class="section remark"><dt>Remarks</dt><dd>This API must only be used for queues with callbacks registered for all expected event types. E.g., not a message queue. </dd></dl>
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @param int|null $timeout_ms int
     * @return int|null int - the number of events served.
     * @since 1.0.0 of librdkafka
     * @link https://docs.confluent.io/3.2.1/clients/librdkafka/rdkafka_8h.html#a13d80084f20a2800e863b97e465ce98e
     */
    public static function rd_kafka_queue_poll_callback(?\FFI\CData $rkqu, ?int $timeout_ms): ?int
    {
        return static::getFFI()->rd_kafka_queue_poll_callback($rkqu, $timeout_ms);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|object|string|null $plug_opaquep void**
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_plugin_f_conf_init_t(?\FFI\CData $conf, $plug_opaquep, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_plugin_f_conf_init_t($conf, $plug_opaquep, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param string|null $name const char*
     * @param string|null $val const char*
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_conf_res_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_conf_set_t(?\FFI\CData $conf, ?string $name, ?string $val, ?\FFI\CData $errstr, ?int $errstr_size, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_conf_set_t($conf, $name, $val, $errstr, $errstr_size, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $new_conf rd_kafka_conf_t*
     * @param \FFI\CData|null $old_conf rd_kafka_conf_t*
     * @param int|null $filter_cnt size_t
     * @param \FFI\CData|null $filter char**
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_conf_dup_t(?\FFI\CData $new_conf, ?\FFI\CData $old_conf, ?int $filter_cnt, ?\FFI\CData $filter, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_conf_dup_t($new_conf, $old_conf, $filter_cnt, $filter, $ic_opaque);
    }

    /**
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_conf_destroy_t($ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_conf_destroy_t($ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_new_t(?\FFI\CData $rk, ?\FFI\CData $conf, $ic_opaque, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_new_t($rk, $conf, $ic_opaque, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_destroy_t(?\FFI\CData $rk, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_destroy_t($rk, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $rkmessage const rd_kafka_message_t*
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_send_t(?\FFI\CData $rk, ?\FFI\CData $rkmessage, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_send_t($rk, $rkmessage, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $rkmessage const rd_kafka_message_t*
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_acknowledgement_t(?\FFI\CData $rk, ?\FFI\CData $rkmessage, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_acknowledgement_t($rk, $rkmessage, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $rkmessage const rd_kafka_message_t*
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_consume_t(?\FFI\CData $rk, ?\FFI\CData $rkmessage, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_consume_t($rk, $rkmessage, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $offsets rd_kafka_topic_partition_list_t*
     * @param int $err rd_kafka_resp_err_t
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_commit_t(?\FFI\CData $rk, ?\FFI\CData $offsets, int $err, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_commit_t($rk, $offsets, $err, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $sockfd int
     * @param string|null $brokername const char*
     * @param int|null $brokerid int32_t
     * @param int|null $ApiKey int16_t
     * @param int|null $ApiVersion int16_t
     * @param int|null $CorrId int32_t
     * @param int|null $size size_t
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_request_sent_t(?\FFI\CData $rk, ?int $sockfd, ?string $brokername, ?int $brokerid, ?int $ApiKey, ?int $ApiVersion, ?int $CorrId, ?int $size, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_request_sent_t($rk, $sockfd, $brokername, $brokerid, $ApiKey, $ApiVersion, $CorrId, $size, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_conf_set rd_kafka_conf_res_t(rd_kafka_interceptor_f_on_conf_set_t*)(rd_kafka_conf_t*, const char*, const char*, char*, size_t, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_interceptor_add_on_conf_set(?\FFI\CData $conf, ?string $ic_name, $on_conf_set, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_conf_interceptor_add_on_conf_set($conf, $ic_name, $on_conf_set, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_conf_dup rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_conf_dup_t*)(rd_kafka_conf_t*, rd_kafka_conf_t*, size_t, char**, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_interceptor_add_on_conf_dup(?\FFI\CData $conf, ?string $ic_name, $on_conf_dup, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_conf_interceptor_add_on_conf_dup($conf, $ic_name, $on_conf_dup, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_conf_destroy rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_conf_destroy_t*)(void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_interceptor_add_on_conf_destroy(?\FFI\CData $conf, ?string $ic_name, $on_conf_destroy, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_conf_interceptor_add_on_conf_destroy($conf, $ic_name, $on_conf_destroy, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $conf rd_kafka_conf_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_new rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_new_t*)(rd_kafka_t*, rd_kafka_conf_t*, void*, char*, size_t)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_conf_interceptor_add_on_new(?\FFI\CData $conf, ?string $ic_name, $on_new, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_conf_interceptor_add_on_new($conf, $ic_name, $on_new, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_destroy rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_destroy_t*)(rd_kafka_t*, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_add_on_destroy(?\FFI\CData $rk, ?string $ic_name, $on_destroy, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_add_on_destroy($rk, $ic_name, $on_destroy, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_send rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_send_t*)(rd_kafka_t*, const rd_kafka_message_t*, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_add_on_send(?\FFI\CData $rk, ?string $ic_name, $on_send, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_add_on_send($rk, $ic_name, $on_send, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_acknowledgement rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_acknowledgement_t*)(rd_kafka_t*, const rd_kafka_message_t*, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_add_on_acknowledgement(?\FFI\CData $rk, ?string $ic_name, $on_acknowledgement, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_add_on_acknowledgement($rk, $ic_name, $on_acknowledgement, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_consume rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_consume_t*)(rd_kafka_t*, const rd_kafka_message_t*, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_add_on_consume(?\FFI\CData $rk, ?string $ic_name, $on_consume, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_add_on_consume($rk, $ic_name, $on_consume, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_commit rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_commit_t*)(rd_kafka_t*, rd_kafka_topic_partition_list_t*, rd_kafka_resp_err_t, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_add_on_commit(?\FFI\CData $rk, ?string $ic_name, $on_commit, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_add_on_commit($rk, $ic_name, $on_commit, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_request_sent rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_request_sent_t*)(rd_kafka_t*, int, const char*, int32_t, int16_t, int16_t, int32_t, size_t, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_interceptor_add_on_request_sent(?\FFI\CData $rk, ?string $ic_name, $on_request_sent, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_add_on_request_sent($rk, $ic_name, $on_request_sent, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $topicres rd_kafka_topic_result_t*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_result_error(?\FFI\CData $topicres): int
    {
        return static::getFFI()->rd_kafka_topic_result_error($topicres);
    }

    /**
     * @param \FFI\CData|null $topicres rd_kafka_topic_result_t*
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_result_error_string(?\FFI\CData $topicres): ?string
    {
        return static::getFFI()->rd_kafka_topic_result_error_string($topicres);
    }

    /**
     * @param \FFI\CData|null $topicres rd_kafka_topic_result_t*
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_topic_result_name(?\FFI\CData $topicres): ?string
    {
        return static::getFFI()->rd_kafka_topic_result_name($topicres);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int $for_api rd_kafka_admin_op_t
     * @return \FFI\CData|null rd_kafka_AdminOptions_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_AdminOptions_new(?\FFI\CData $rk, int $for_api): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_AdminOptions_new($rk, $for_api);
    }

    /**
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_AdminOptions_destroy(?\FFI\CData $options): void
    {
        static::getFFI()->rd_kafka_AdminOptions_destroy($options);
    }

    /**
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param int|null $timeout_ms int
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_AdminOptions_set_request_timeout(?\FFI\CData $options, ?int $timeout_ms, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_AdminOptions_set_request_timeout($options, $timeout_ms, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param int|null $timeout_ms int
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_AdminOptions_set_operation_timeout(?\FFI\CData $options, ?int $timeout_ms, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_AdminOptions_set_operation_timeout($options, $timeout_ms, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param int|null $true_or_false int
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_AdminOptions_set_validate_only(?\FFI\CData $options, ?int $true_or_false, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_AdminOptions_set_validate_only($options, $true_or_false, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param int|null $broker_id int32_t
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_AdminOptions_set_broker(?\FFI\CData $options, ?int $broker_id, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_AdminOptions_set_broker($options, $broker_id, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param \FFI\CData|object|string|null $opaque void*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_AdminOptions_set_opaque(?\FFI\CData $options, $opaque): void
    {
        static::getFFI()->rd_kafka_AdminOptions_set_opaque($options, $opaque);
    }

    /**
     * @param string|null $topic const char*
     * @param int|null $num_partitions int
     * @param int|null $replication_factor int
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return \FFI\CData|null rd_kafka_NewTopic_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_NewTopic_new(?string $topic, ?int $num_partitions, ?int $replication_factor, ?\FFI\CData $errstr, ?int $errstr_size): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_NewTopic_new($topic, $num_partitions, $replication_factor, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $new_topic rd_kafka_NewTopic_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_NewTopic_destroy(?\FFI\CData $new_topic): void
    {
        static::getFFI()->rd_kafka_NewTopic_destroy($new_topic);
    }

    /**
     * @param \FFI\CData|null $new_topics rd_kafka_NewTopic_t**
     * @param int|null $new_topic_cnt size_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_NewTopic_destroy_array(?\FFI\CData $new_topics, ?int $new_topic_cnt): void
    {
        static::getFFI()->rd_kafka_NewTopic_destroy_array($new_topics, $new_topic_cnt);
    }

    /**
     * @param \FFI\CData|null $new_topic rd_kafka_NewTopic_t*
     * @param int|null $partition int32_t
     * @param \FFI\CData|null $broker_ids int32_t*
     * @param int|null $broker_id_cnt size_t
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_NewTopic_set_replica_assignment(?\FFI\CData $new_topic, ?int $partition, ?\FFI\CData $broker_ids, ?int $broker_id_cnt, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_NewTopic_set_replica_assignment($new_topic, $partition, $broker_ids, $broker_id_cnt, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $new_topic rd_kafka_NewTopic_t*
     * @param string|null $name const char*
     * @param string|null $value const char*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_NewTopic_set_config(?\FFI\CData $new_topic, ?string $name, ?string $value): int
    {
        return static::getFFI()->rd_kafka_NewTopic_set_config($new_topic, $name, $value);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $new_topics rd_kafka_NewTopic_t**
     * @param int|null $new_topic_cnt size_t
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_CreateTopics(?\FFI\CData $rk, ?\FFI\CData $new_topics, ?int $new_topic_cnt, ?\FFI\CData $options, ?\FFI\CData $rkqu): void
    {
        static::getFFI()->rd_kafka_CreateTopics($rk, $new_topics, $new_topic_cnt, $options, $rkqu);
    }

    /**
     * @param \FFI\CData|null $result const rd_kafka_CreateTopics_result_t*
     * @param \FFI\CData|null $cntp size_t*
     * @return \FFI\CData|null const rd_kafka_topic_result_t**
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_CreateTopics_result_topics(?\FFI\CData $result, ?\FFI\CData $cntp): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_CreateTopics_result_topics($result, $cntp);
    }

    /**
     * @param string|null $topic const char*
     * @return \FFI\CData|null rd_kafka_DeleteTopic_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_DeleteTopic_new(?string $topic): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_DeleteTopic_new($topic);
    }

    /**
     * @param \FFI\CData|null $del_topic rd_kafka_DeleteTopic_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_DeleteTopic_destroy(?\FFI\CData $del_topic): void
    {
        static::getFFI()->rd_kafka_DeleteTopic_destroy($del_topic);
    }

    /**
     * @param \FFI\CData|null $del_topics rd_kafka_DeleteTopic_t**
     * @param int|null $del_topic_cnt size_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_DeleteTopic_destroy_array(?\FFI\CData $del_topics, ?int $del_topic_cnt): void
    {
        static::getFFI()->rd_kafka_DeleteTopic_destroy_array($del_topics, $del_topic_cnt);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $del_topics rd_kafka_DeleteTopic_t**
     * @param int|null $del_topic_cnt size_t
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_DeleteTopics(?\FFI\CData $rk, ?\FFI\CData $del_topics, ?int $del_topic_cnt, ?\FFI\CData $options, ?\FFI\CData $rkqu): void
    {
        static::getFFI()->rd_kafka_DeleteTopics($rk, $del_topics, $del_topic_cnt, $options, $rkqu);
    }

    /**
     * @param \FFI\CData|null $result const rd_kafka_DeleteTopics_result_t*
     * @param \FFI\CData|null $cntp size_t*
     * @return \FFI\CData|null const rd_kafka_topic_result_t**
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_DeleteTopics_result_topics(?\FFI\CData $result, ?\FFI\CData $cntp): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_DeleteTopics_result_topics($result, $cntp);
    }

    /**
     * @param string|null $topic const char*
     * @param int|null $new_total_cnt size_t
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return \FFI\CData|null rd_kafka_NewPartitions_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_NewPartitions_new(?string $topic, ?int $new_total_cnt, ?\FFI\CData $errstr, ?int $errstr_size): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_NewPartitions_new($topic, $new_total_cnt, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $new_parts rd_kafka_NewPartitions_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_NewPartitions_destroy(?\FFI\CData $new_parts): void
    {
        static::getFFI()->rd_kafka_NewPartitions_destroy($new_parts);
    }

    /**
     * @param \FFI\CData|null $new_parts rd_kafka_NewPartitions_t**
     * @param int|null $new_parts_cnt size_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_NewPartitions_destroy_array(?\FFI\CData $new_parts, ?int $new_parts_cnt): void
    {
        static::getFFI()->rd_kafka_NewPartitions_destroy_array($new_parts, $new_parts_cnt);
    }

    /**
     * @param \FFI\CData|null $new_parts rd_kafka_NewPartitions_t*
     * @param int|null $new_partition_idx int32_t
     * @param \FFI\CData|null $broker_ids int32_t*
     * @param int|null $broker_id_cnt size_t
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_NewPartitions_set_replica_assignment(?\FFI\CData $new_parts, ?int $new_partition_idx, ?\FFI\CData $broker_ids, ?int $broker_id_cnt, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_NewPartitions_set_replica_assignment($new_parts, $new_partition_idx, $broker_ids, $broker_id_cnt, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $new_parts rd_kafka_NewPartitions_t**
     * @param int|null $new_parts_cnt size_t
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_CreatePartitions(?\FFI\CData $rk, ?\FFI\CData $new_parts, ?int $new_parts_cnt, ?\FFI\CData $options, ?\FFI\CData $rkqu): void
    {
        static::getFFI()->rd_kafka_CreatePartitions($rk, $new_parts, $new_parts_cnt, $options, $rkqu);
    }

    /**
     * @param \FFI\CData|null $result const rd_kafka_CreatePartitions_result_t*
     * @param \FFI\CData|null $cntp size_t*
     * @return \FFI\CData|null const rd_kafka_topic_result_t**
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_CreatePartitions_result_topics(?\FFI\CData $result, ?\FFI\CData $cntp): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_CreatePartitions_result_topics($result, $cntp);
    }

    /**
     * @param int $confsource rd_kafka_ConfigSource_t
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigSource_name(int $confsource): ?string
    {
        return static::getFFI()->rd_kafka_ConfigSource_name($confsource);
    }

    /**
     * @param \FFI\CData|null $entry rd_kafka_ConfigEntry_t*
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigEntry_name(?\FFI\CData $entry): ?string
    {
        return static::getFFI()->rd_kafka_ConfigEntry_name($entry);
    }

    /**
     * @param \FFI\CData|null $entry rd_kafka_ConfigEntry_t*
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigEntry_value(?\FFI\CData $entry): ?string
    {
        return static::getFFI()->rd_kafka_ConfigEntry_value($entry);
    }

    /**
     * @param \FFI\CData|null $entry rd_kafka_ConfigEntry_t*
     * @return int rd_kafka_ConfigSource_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigEntry_source(?\FFI\CData $entry): int
    {
        return static::getFFI()->rd_kafka_ConfigEntry_source($entry);
    }

    /**
     * @param \FFI\CData|null $entry rd_kafka_ConfigEntry_t*
     * @return int|null int
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigEntry_is_read_only(?\FFI\CData $entry): ?int
    {
        return static::getFFI()->rd_kafka_ConfigEntry_is_read_only($entry);
    }

    /**
     * @param \FFI\CData|null $entry rd_kafka_ConfigEntry_t*
     * @return int|null int
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigEntry_is_default(?\FFI\CData $entry): ?int
    {
        return static::getFFI()->rd_kafka_ConfigEntry_is_default($entry);
    }

    /**
     * @param \FFI\CData|null $entry rd_kafka_ConfigEntry_t*
     * @return int|null int
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigEntry_is_sensitive(?\FFI\CData $entry): ?int
    {
        return static::getFFI()->rd_kafka_ConfigEntry_is_sensitive($entry);
    }

    /**
     * @param \FFI\CData|null $entry rd_kafka_ConfigEntry_t*
     * @return int|null int
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigEntry_is_synonym(?\FFI\CData $entry): ?int
    {
        return static::getFFI()->rd_kafka_ConfigEntry_is_synonym($entry);
    }

    /**
     * @param \FFI\CData|null $entry rd_kafka_ConfigEntry_t*
     * @param \FFI\CData|null $cntp size_t*
     * @return \FFI\CData|null const rd_kafka_ConfigEntry_t**
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigEntry_synonyms(?\FFI\CData $entry, ?\FFI\CData $cntp): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_ConfigEntry_synonyms($entry, $cntp);
    }

    /**
     * @param int $restype rd_kafka_ResourceType_t
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ResourceType_name(int $restype): ?string
    {
        return static::getFFI()->rd_kafka_ResourceType_name($restype);
    }

    /**
     * @param int $restype rd_kafka_ResourceType_t
     * @param string|null $resname const char*
     * @return \FFI\CData|null rd_kafka_ConfigResource_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigResource_new(int $restype, ?string $resname): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_ConfigResource_new($restype, $resname);
    }

    /**
     * @param \FFI\CData|null $config rd_kafka_ConfigResource_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigResource_destroy(?\FFI\CData $config): void
    {
        static::getFFI()->rd_kafka_ConfigResource_destroy($config);
    }

    /**
     * @param \FFI\CData|null $config rd_kafka_ConfigResource_t**
     * @param int|null $config_cnt size_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigResource_destroy_array(?\FFI\CData $config, ?int $config_cnt): void
    {
        static::getFFI()->rd_kafka_ConfigResource_destroy_array($config, $config_cnt);
    }

    /**
     * @param \FFI\CData|null $config rd_kafka_ConfigResource_t*
     * @param string|null $name const char*
     * @param string|null $value const char*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigResource_set_config(?\FFI\CData $config, ?string $name, ?string $value): int
    {
        return static::getFFI()->rd_kafka_ConfigResource_set_config($config, $name, $value);
    }

    /**
     * @param \FFI\CData|null $config rd_kafka_ConfigResource_t*
     * @param \FFI\CData|null $cntp size_t*
     * @return \FFI\CData|null const rd_kafka_ConfigEntry_t**
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigResource_configs(?\FFI\CData $config, ?\FFI\CData $cntp): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_ConfigResource_configs($config, $cntp);
    }

    /**
     * @param \FFI\CData|null $config rd_kafka_ConfigResource_t*
     * @return int rd_kafka_ResourceType_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigResource_type(?\FFI\CData $config): int
    {
        return static::getFFI()->rd_kafka_ConfigResource_type($config);
    }

    /**
     * @param \FFI\CData|null $config rd_kafka_ConfigResource_t*
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigResource_name(?\FFI\CData $config): ?string
    {
        return static::getFFI()->rd_kafka_ConfigResource_name($config);
    }

    /**
     * @param \FFI\CData|null $config rd_kafka_ConfigResource_t*
     * @return int rd_kafka_resp_err_t
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigResource_error(?\FFI\CData $config): int
    {
        return static::getFFI()->rd_kafka_ConfigResource_error($config);
    }

    /**
     * @param \FFI\CData|null $config rd_kafka_ConfigResource_t*
     * @return string|null const char*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_ConfigResource_error_string(?\FFI\CData $config): ?string
    {
        return static::getFFI()->rd_kafka_ConfigResource_error_string($config);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $configs rd_kafka_ConfigResource_t**
     * @param int|null $config_cnt size_t
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_AlterConfigs(?\FFI\CData $rk, ?\FFI\CData $configs, ?int $config_cnt, ?\FFI\CData $options, ?\FFI\CData $rkqu): void
    {
        static::getFFI()->rd_kafka_AlterConfigs($rk, $configs, $config_cnt, $options, $rkqu);
    }

    /**
     * @param \FFI\CData|null $result const rd_kafka_AlterConfigs_result_t*
     * @param \FFI\CData|null $cntp size_t*
     * @return \FFI\CData|null const rd_kafka_ConfigResource_t**
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_AlterConfigs_result_resources(?\FFI\CData $result, ?\FFI\CData $cntp): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_AlterConfigs_result_resources($result, $cntp);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $configs const rd_kafka_ConfigResource_t**
     * @param int|null $config_cnt size_t
     * @param \FFI\CData|null $options rd_kafka_AdminOptions_t*
     * @param \FFI\CData|null $rkqu rd_kafka_queue_t*
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_DescribeConfigs(?\FFI\CData $rk, ?\FFI\CData $configs, ?int $config_cnt, ?\FFI\CData $options, ?\FFI\CData $rkqu): void
    {
        static::getFFI()->rd_kafka_DescribeConfigs($rk, $configs, $config_cnt, $options, $rkqu);
    }

    /**
     * @param \FFI\CData|null $result const rd_kafka_DescribeConfigs_result_t*
     * @param \FFI\CData|null $cntp size_t*
     * @return \FFI\CData|null const rd_kafka_ConfigResource_t**
     * @since 1.0.0 of librdkafka
     */
    public static function rd_kafka_DescribeConfigs_result_resources(?\FFI\CData $result, ?\FFI\CData $cntp): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_DescribeConfigs_result_resources($result, $cntp);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return \FFI\CData|null const rd_kafka_conf_t*
     * @since 1.1.0 of librdkafka
     */
    public static function rd_kafka_conf(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_conf($rk);
    }

    /**
     * @param \FFI\CData|null $conf const rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $oauthbearer_token_refresh_cb void(*)(rd_kafka_t*, const char*, void*)
     * @since 1.1.0 of librdkafka
     */
    public static function rd_kafka_conf_set_oauthbearer_token_refresh_cb(?\FFI\CData $conf, $oauthbearer_token_refresh_cb): void
    {
        static::getFFI()->rd_kafka_conf_set_oauthbearer_token_refresh_cb($conf, $oauthbearer_token_refresh_cb);
    }

    /**
     * @param \FFI\CData|null $conf const rd_kafka_conf_t*
     * @param \FFI\CData|\Closure $ssl_cert_verify_cb int(*)(rd_kafka_t*, const char*, int32_t, int*, int, const char*, size_t, char*, size_t, void*)
     * @return int rd_kafka_conf_res_t
     * @since 1.1.0 of librdkafka
     */
    public static function rd_kafka_conf_set_ssl_cert_verify_cb(?\FFI\CData $conf, $ssl_cert_verify_cb): int
    {
        return static::getFFI()->rd_kafka_conf_set_ssl_cert_verify_cb($conf, $ssl_cert_verify_cb);
    }

    /**
     * @param \FFI\CData|null $conf const rd_kafka_conf_t*
     * @param int $cert_type rd_kafka_cert_type_t
     * @param int $cert_enc rd_kafka_cert_enc_t
     * @param \FFI\CData|object|string|null $buffer void*
     * @param int|null $size size_t
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_conf_res_t
     * @since 1.1.0 of librdkafka
     */
    public static function rd_kafka_conf_set_ssl_cert(?\FFI\CData $conf, int $cert_type, int $cert_enc, $buffer, ?int $size, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_conf_set_ssl_cert($conf, $cert_type, $cert_enc, $buffer, $size, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @return string|null const char*
     * @since 1.1.0 of librdkafka
     */
    public static function rd_kafka_event_config_string(?\FFI\CData $rkev): ?string
    {
        return static::getFFI()->rd_kafka_event_config_string($rkev);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $token_value const char*
     * @param int|null $md_lifetime_ms int64_t
     * @param string|null $md_principal_name const char*
     * @param \FFI\CData|null $extensions char**
     * @param int|null $extension_size size_t
     * @param \FFI\CData|null $errstr char*
     * @param int|null $errstr_size size_t
     * @return int rd_kafka_resp_err_t
     * @since 1.1.0 of librdkafka
     */
    public static function rd_kafka_oauthbearer_set_token(?\FFI\CData $rk, ?string $token_value, ?int $md_lifetime_ms, ?string $md_principal_name, ?\FFI\CData $extensions, ?int $extension_size, ?\FFI\CData $errstr, ?int $errstr_size): int
    {
        return static::getFFI()->rd_kafka_oauthbearer_set_token($rk, $token_value, $md_lifetime_ms, $md_principal_name, $extensions, $extension_size, $errstr, $errstr_size);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $errstr const char*
     * @return int rd_kafka_resp_err_t
     * @since 1.1.0 of librdkafka
     */
    public static function rd_kafka_oauthbearer_set_token_failure(?\FFI\CData $rk, ?string $errstr): int
    {
        return static::getFFI()->rd_kafka_oauthbearer_set_token_failure($rk, $errstr);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int $thread_type rd_kafka_thread_type_t
     * @param string|null $thread_name const char*
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.2.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_thread_start_t(?\FFI\CData $rk, int $thread_type, ?string $thread_name, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_thread_start_t($rk, $thread_type, $thread_name, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int $thread_type rd_kafka_thread_type_t
     * @param string|null $thread_name const char*
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.2.0 of librdkafka
     */
    public static function rd_kafka_interceptor_f_on_thread_exit_t(?\FFI\CData $rk, int $thread_type, ?string $thread_name, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_f_on_thread_exit_t($rk, $thread_type, $thread_name, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_thread_start rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_thread_start_t*)(rd_kafka_t*, rd_kafka_thread_type_t, const char*, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.2.0 of librdkafka
     */
    public static function rd_kafka_interceptor_add_on_thread_start(?\FFI\CData $rk, ?string $ic_name, $on_thread_start, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_add_on_thread_start($rk, $ic_name, $on_thread_start, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param string|null $ic_name const char*
     * @param \FFI\CData|\Closure $on_thread_exit rd_kafka_resp_err_t(rd_kafka_interceptor_f_on_thread_exit_t*)(rd_kafka_t*, rd_kafka_thread_type_t, const char*, void*)
     * @param \FFI\CData|object|string|null $ic_opaque void*
     * @return int rd_kafka_resp_err_t
     * @since 1.2.0 of librdkafka
     */
    public static function rd_kafka_interceptor_add_on_thread_exit(?\FFI\CData $rk, ?string $ic_name, $on_thread_exit, $ic_opaque): int
    {
        return static::getFFI()->rd_kafka_interceptor_add_on_thread_exit($rk, $ic_name, $on_thread_exit, $ic_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $broker_cnt int
     * @return \FFI\CData|null rd_kafka_mock_cluster_t*
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_cluster_new(?\FFI\CData $rk, ?int $broker_cnt): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_mock_cluster_new($rk, $broker_cnt);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_cluster_destroy(?\FFI\CData $mcluster): void
    {
        static::getFFI()->rd_kafka_mock_cluster_destroy($mcluster);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @return \FFI\CData|null rd_kafka_t*
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_cluster_handle(?\FFI\CData $mcluster): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_mock_cluster_handle($mcluster);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @return string|null const char*
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_cluster_bootstraps(?\FFI\CData $mcluster): ?string
    {
        return static::getFFI()->rd_kafka_mock_cluster_bootstraps($mcluster);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param int|null $ApiKey int16_t
     * @param int|null $cnt size_t
     * @param mixed ...$args
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_push_request_errors(?\FFI\CData $mcluster, ?int $ApiKey, ?int $cnt, ...$args): void
    {
        static::getFFI()->rd_kafka_mock_push_request_errors($mcluster, $ApiKey, $cnt, ...$args);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param string|null $topic const char*
     * @param int $err rd_kafka_resp_err_t
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_topic_set_error(?\FFI\CData $mcluster, ?string $topic, int $err): void
    {
        static::getFFI()->rd_kafka_mock_topic_set_error($mcluster, $topic, $err);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param string|null $topic const char*
     * @param int|null $partition int32_t
     * @param int|null $broker_id int32_t
     * @return int rd_kafka_resp_err_t
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_partition_set_leader(?\FFI\CData $mcluster, ?string $topic, ?int $partition, ?int $broker_id): int
    {
        return static::getFFI()->rd_kafka_mock_partition_set_leader($mcluster, $topic, $partition, $broker_id);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param string|null $topic const char*
     * @param int|null $partition int32_t
     * @param int|null $broker_id int32_t
     * @return int rd_kafka_resp_err_t
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_partition_set_follower(?\FFI\CData $mcluster, ?string $topic, ?int $partition, ?int $broker_id): int
    {
        return static::getFFI()->rd_kafka_mock_partition_set_follower($mcluster, $topic, $partition, $broker_id);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param string|null $topic const char*
     * @param int|null $partition int32_t
     * @param int|null $lo int64_t
     * @param int|null $hi int64_t
     * @return int rd_kafka_resp_err_t
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_partition_set_follower_wmarks(?\FFI\CData $mcluster, ?string $topic, ?int $partition, ?int $lo, ?int $hi): int
    {
        return static::getFFI()->rd_kafka_mock_partition_set_follower_wmarks($mcluster, $topic, $partition, $lo, $hi);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param int|null $broker_id int32_t
     * @param string|null $rack const char*
     * @return int rd_kafka_resp_err_t
     * @since 1.3.0 of librdkafka
     */
    public static function rd_kafka_mock_broker_set_rack(?\FFI\CData $mcluster, ?int $broker_id, ?string $rack): int
    {
        return static::getFFI()->rd_kafka_mock_broker_set_rack($mcluster, $broker_id, $rack);
    }

    /**
     * @param \FFI\CData|null $error rd_kafka_error_t*
     * @return int rd_kafka_resp_err_t
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_error_code(?\FFI\CData $error): int
    {
        return static::getFFI()->rd_kafka_error_code($error);
    }

    /**
     * @param \FFI\CData|null $error rd_kafka_error_t*
     * @return string|null const char*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_error_name(?\FFI\CData $error): ?string
    {
        return static::getFFI()->rd_kafka_error_name($error);
    }

    /**
     * @param \FFI\CData|null $error rd_kafka_error_t*
     * @return string|null const char*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_error_string(?\FFI\CData $error): ?string
    {
        return static::getFFI()->rd_kafka_error_string($error);
    }

    /**
     * @param \FFI\CData|null $error rd_kafka_error_t*
     * @return int|null int
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_error_is_fatal(?\FFI\CData $error): ?int
    {
        return static::getFFI()->rd_kafka_error_is_fatal($error);
    }

    /**
     * @param \FFI\CData|null $error rd_kafka_error_t*
     * @return int|null int
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_error_is_retriable(?\FFI\CData $error): ?int
    {
        return static::getFFI()->rd_kafka_error_is_retriable($error);
    }

    /**
     * @param \FFI\CData|null $error rd_kafka_error_t*
     * @return int|null int
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_error_txn_requires_abort(?\FFI\CData $error): ?int
    {
        return static::getFFI()->rd_kafka_error_txn_requires_abort($error);
    }

    /**
     * @param \FFI\CData|null $error rd_kafka_error_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_error_destroy(?\FFI\CData $error): void
    {
        static::getFFI()->rd_kafka_error_destroy($error);
    }

    /**
     * @param int $code rd_kafka_resp_err_t
     * @param string|null $fmt const char*
     * @param mixed ...$args
     * @return \FFI\CData|null rd_kafka_error_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_error_new(int $code, ?string $fmt, ...$args): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_error_new($code, $fmt, ...$args);
    }

    /**
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param \FFI\CData|object|string|null $key void*
     * @param int|null $keylen size_t
     * @param int|null $partition_cnt int32_t
     * @param \FFI\CData|object|string|null $rkt_opaque void*
     * @param \FFI\CData|object|string|null $msg_opaque void*
     * @return int|null int32_t
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_msg_partitioner_fnv1a(?\FFI\CData $rkt, $key, ?int $keylen, ?int $partition_cnt, $rkt_opaque, $msg_opaque): ?int
    {
        return static::getFFI()->rd_kafka_msg_partitioner_fnv1a($rkt, $key, $keylen, $partition_cnt, $rkt_opaque, $msg_opaque);
    }

    /**
     * @param \FFI\CData|null $rkt rd_kafka_topic_t*
     * @param \FFI\CData|object|string|null $key void*
     * @param int|null $keylen size_t
     * @param int|null $partition_cnt int32_t
     * @param \FFI\CData|object|string|null $rkt_opaque void*
     * @param \FFI\CData|object|string|null $msg_opaque void*
     * @return int|null int32_t
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_msg_partitioner_fnv1a_random(?\FFI\CData $rkt, $key, ?int $keylen, ?int $partition_cnt, $rkt_opaque, $msg_opaque): ?int
    {
        return static::getFFI()->rd_kafka_msg_partitioner_fnv1a_random($rkt, $key, $keylen, $partition_cnt, $rkt_opaque, $msg_opaque);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return \FFI\CData|null rd_kafka_consumer_group_metadata_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_consumer_group_metadata(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_consumer_group_metadata($rk);
    }

    /**
     * @param string|null $group_id const char*
     * @return \FFI\CData|null rd_kafka_consumer_group_metadata_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_consumer_group_metadata_new(?string $group_id): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_consumer_group_metadata_new($group_id);
    }

    /**
     * @param \FFI\CData|null $arg0 rd_kafka_consumer_group_metadata_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_consumer_group_metadata_destroy(?\FFI\CData $arg0): void
    {
        static::getFFI()->rd_kafka_consumer_group_metadata_destroy($arg0);
    }

    /**
     * @param \FFI\CData|null $cgmd rd_kafka_consumer_group_metadata_t*
     * @param \FFI\CData|object|string|null $bufferp void**
     * @param \FFI\CData|null $sizep size_t*
     * @return \FFI\CData|null rd_kafka_error_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_consumer_group_metadata_write(?\FFI\CData $cgmd, $bufferp, ?\FFI\CData $sizep): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_consumer_group_metadata_write($cgmd, $bufferp, $sizep);
    }

    /**
     * @param \FFI\CData|null $cgmdp rd_kafka_consumer_group_metadata_t**
     * @param \FFI\CData|object|string|null $buffer void*
     * @param int|null $size size_t
     * @return \FFI\CData|null rd_kafka_error_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_consumer_group_metadata_read(?\FFI\CData $cgmdp, $buffer, ?int $size): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_consumer_group_metadata_read($cgmdp, $buffer, $size);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $timeout_ms int
     * @return \FFI\CData|null rd_kafka_error_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_init_transactions(?\FFI\CData $rk, ?int $timeout_ms): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_init_transactions($rk, $timeout_ms);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return \FFI\CData|null rd_kafka_error_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_begin_transaction(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_begin_transaction($rk);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $offsets rd_kafka_topic_partition_list_t*
     * @param \FFI\CData|null $cgmetadata rd_kafka_consumer_group_metadata_t*
     * @param int|null $timeout_ms int
     * @return \FFI\CData|null rd_kafka_error_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_send_offsets_to_transaction(?\FFI\CData $rk, ?\FFI\CData $offsets, ?\FFI\CData $cgmetadata, ?int $timeout_ms): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_send_offsets_to_transaction($rk, $offsets, $cgmetadata, $timeout_ms);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $timeout_ms int
     * @return \FFI\CData|null rd_kafka_error_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_commit_transaction(?\FFI\CData $rk, ?int $timeout_ms): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_commit_transaction($rk, $timeout_ms);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param int|null $timeout_ms int
     * @return \FFI\CData|null rd_kafka_error_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_abort_transaction(?\FFI\CData $rk, ?int $timeout_ms): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_abort_transaction($rk, $timeout_ms);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @return \FFI\CData|null rd_kafka_mock_cluster_t*
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_handle_mock_cluster(?\FFI\CData $rk): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_handle_mock_cluster($rk);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param string|null $topic const char*
     * @param int|null $partition_cnt int
     * @param int|null $replication_factor int
     * @return int rd_kafka_resp_err_t
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_mock_topic_create(?\FFI\CData $mcluster, ?string $topic, ?int $partition_cnt, ?int $replication_factor): int
    {
        return static::getFFI()->rd_kafka_mock_topic_create($mcluster, $topic, $partition_cnt, $replication_factor);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param int|null $broker_id int32_t
     * @return int rd_kafka_resp_err_t
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_mock_broker_set_down(?\FFI\CData $mcluster, ?int $broker_id): int
    {
        return static::getFFI()->rd_kafka_mock_broker_set_down($mcluster, $broker_id);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param int|null $broker_id int32_t
     * @return int rd_kafka_resp_err_t
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_mock_broker_set_up(?\FFI\CData $mcluster, ?int $broker_id): int
    {
        return static::getFFI()->rd_kafka_mock_broker_set_up($mcluster, $broker_id);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param string|null $key_type const char*
     * @param string|null $key const char*
     * @param int|null $broker_id int32_t
     * @return int rd_kafka_resp_err_t
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_mock_coordinator_set(?\FFI\CData $mcluster, ?string $key_type, ?string $key, ?int $broker_id): int
    {
        return static::getFFI()->rd_kafka_mock_coordinator_set($mcluster, $key_type, $key, $broker_id);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param int|null $ApiKey int16_t
     * @param int|null $MinVersion int16_t
     * @param int|null $MaxVersion int16_t
     * @return int rd_kafka_resp_err_t
     * @since 1.4.0 of librdkafka
     */
    public static function rd_kafka_mock_set_apiversion(?\FFI\CData $mcluster, ?int $ApiKey, ?int $MinVersion, ?int $MaxVersion): int
    {
        return static::getFFI()->rd_kafka_mock_set_apiversion($mcluster, $ApiKey, $MinVersion, $MaxVersion);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param int|null $broker_id int32_t
     * @param int|null $rtt_ms int
     * @return int rd_kafka_resp_err_t
     * @since 1.4.4 of librdkafka
     */
    public static function rd_kafka_mock_broker_set_rtt(?\FFI\CData $mcluster, ?int $broker_id, ?int $rtt_ms): int
    {
        return static::getFFI()->rd_kafka_mock_broker_set_rtt($mcluster, $broker_id, $rtt_ms);
    }

    /**
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @return string|null const char*
     * @since 1.5.0 of librdkafka
     */
    public static function rd_kafka_message_errstr(?\FFI\CData $rkmessage): ?string
    {
        return static::getFFI()->rd_kafka_message_errstr($rkmessage);
    }

    /**
     * @param \FFI\CData|null $rkmessage rd_kafka_message_t*
     * @return int|null int32_t
     * @since 1.5.0 of librdkafka
     */
    public static function rd_kafka_message_broker_id(?\FFI\CData $rkmessage): ?int
    {
        return static::getFFI()->rd_kafka_message_broker_id($rkmessage);
    }

    /**
     * @param \FFI\CData|null $rk rd_kafka_t*
     * @param \FFI\CData|null $vus rd_kafka_vu_t*
     * @param int|null $cnt size_t
     * @return \FFI\CData|null rd_kafka_error_t*
     * @since 1.5.0 of librdkafka
     */
    public static function rd_kafka_produceva(?\FFI\CData $rk, ?\FFI\CData $vus, ?int $cnt): ?\FFI\CData
    {
        return static::getFFI()->rd_kafka_produceva($rk, $vus, $cnt);
    }

    /**
     * @param \FFI\CData|null $rkev rd_kafka_event_t*
     * @param \FFI\CData|null $dst char*
     * @param int|null $dstsize size_t
     * @return int|null int
     * @since 1.5.0 of librdkafka
     */
    public static function rd_kafka_event_debug_contexts(?\FFI\CData $rkev, ?\FFI\CData $dst, ?int $dstsize): ?int
    {
        return static::getFFI()->rd_kafka_event_debug_contexts($rkev, $dst, $dstsize);
    }

    /**
     * @param \FFI\CData|null $mcluster rd_kafka_mock_cluster_t*
     * @param int|null $broker_id int32_t
     * @param int|null $ApiKey int16_t
     * @param int|null $cnt size_t
     * @param mixed ...$args
     * @return int rd_kafka_resp_err_t
     * @since 1.5.0 of librdkafka
     */
    public static function rd_kafka_mock_broker_push_request_errors(?\FFI\CData $mcluster, ?int $broker_id, ?int $ApiKey, ?int $cnt, ...$args): int
    {
        return static::getFFI()->rd_kafka_mock_broker_push_request_errors($mcluster, $broker_id, $ApiKey, $cnt, ...$args);
    }
}
